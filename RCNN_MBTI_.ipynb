{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xKeo6sM2cvf"
      },
      "outputs": [],
      "source": [
        " ! pip install -q kaggle\n",
        " ! mkdir ~/.kaggle\n",
        " ! cp /content/kaggle.json ~/.kaggle/\n",
        " ! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw4Ew4tI2yZl",
        "outputId": "0b32262a-02b1-4618-84c6-73ec2d3720b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading mbti-type.zip to /content\n",
            " 45% 11.0M/24.4M [00:00<00:00, 114MB/s]\n",
            "100% 24.4M/24.4M [00:00<00:00, 160MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download datasnaek/mbti-type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5x_3x4a207R",
        "outputId": "05caea71-76f9-4917-aa06-9a1935e6fb3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/mbti-type.zip\n",
            "  inflating: mbti_1.csv              \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/mbti-type.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1Yx3tX723D0",
        "outputId": "21ec88f4-e406-4f14-93e9-acdce0df6720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting pyahocorasick\n",
            "  Downloading pyahocorasick-2.0.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anyascii\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions\n",
        "import contractions\n",
        "def fix_contractions(df, column_name = \"posts\", new_column=\"cleaned_post\"):\n",
        "    df[new_column] = df[column_name].apply(lambda x: contractions.fix(x))\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3Lj0hpR3FS5"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def clean_data(df, column_name = \"cleaned_post\"):\n",
        "    df[column_name] = df[column_name].apply(lambda x: x.lower())\n",
        "    df[column_name] = df[column_name].apply(lambda x: re.sub(r'@([a-zA-Z0-9_]{1,50})', '', x))\n",
        "    df[column_name] = df[column_name].apply(lambda x: re.sub(r'#([a-zA-Z0-9_]{1,50})', '', x))\n",
        "    df[column_name] = df[column_name].apply(lambda x: re.sub(r'http[s]?://\\S+', '', x))\n",
        "    df[column_name] = df[column_name].apply(lambda x: re.sub(r'[^A-Za-z]+', ' ', x))\n",
        "    df[column_name] = df[column_name].apply(lambda x: re.sub(r' +', ' ', x))\n",
        "    df[column_name] = df[column_name].apply(lambda x: \" \".join([word for word in x.split() if not len(word) <3]))\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeOj2kfD3N3i",
        "outputId": "4771d660-7f87-4293-fbb9-395cb9084735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "!pip install nltk\n",
        "import nltk \n",
        "nltk.download(\"all\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp6wDdTl3RWf"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "def remove_stopwords(data, stopword_list, column=\"cleaned_post\"):\n",
        "    data[column] = data[column].apply(word_tokenize)\n",
        "    data[column] = data[column].apply(lambda x: [word for word in x if not word in stopword_list])\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnXjtdD03Y4g"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "def apply_lemmatization(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(w) for w in text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UY5ViTO63Z2e"
      },
      "outputs": [],
      "source": [
        "def lemmatize(data, stopword_list, column=\"cleaned_post\"):\n",
        "    data[column] = data[column].apply(apply_lemmatization)\n",
        "    data[column] = data[column].apply(\" \".join)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ggsy_j803b4c"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopword_list = stopwords.words(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJmCshBp3yKv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"mbti_1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYREzJMb3eUF"
      },
      "outputs": [],
      "source": [
        "data = fix_contractions(data)\n",
        "data = clean_data(data)\n",
        "data = remove_stopwords(data, stopword_list)\n",
        "data = lemmatize(data, stopword_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EHGhGEIL3grQ",
        "outputId": "c3eecd97-60e4-4e61-901b-de90248cdb58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   type                                              posts  \\\n",
              "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   \n",
              "1  ENTP  'I'm finding the lack of me in these posts ver...   \n",
              "2  INTP  'Good one  _____   https://www.youtube.com/wat...   \n",
              "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...   \n",
              "4  ENTJ  'You're fired.|||That's another silly misconce...   \n",
              "\n",
              "                                        cleaned_post  \n",
              "0  intj moment sportscenter top ten play prank li...  \n",
              "1  finding lack post alarming sex boring position...  \n",
              "2  good one course say know blessing curse absolu...  \n",
              "3  dear intp enjoyed conversation day esoteric ga...  \n",
              "4  fired another silly misconception approaching ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa1d13b5-42de-4bbb-834a-b1cbca40ac0f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "      <th>cleaned_post</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
              "      <td>intj moment sportscenter top ten play prank li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
              "      <td>finding lack post alarming sex boring position...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>INTP</td>\n",
              "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
              "      <td>good one course say know blessing curse absolu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
              "      <td>dear intp enjoyed conversation day esoteric ga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>'You're fired.|||That's another silly misconce...</td>\n",
              "      <td>fired another silly misconception approaching ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa1d13b5-42de-4bbb-834a-b1cbca40ac0f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa1d13b5-42de-4bbb-834a-b1cbca40ac0f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa1d13b5-42de-4bbb-834a-b1cbca40ac0f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RA5L8CaBZm3I",
        "outputId": "f6f1936e-02d9-4f93-923d-550d13055279"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        cleaned_post  type\n",
              "0  intj moment sportscenter top ten play prank li...  INFJ\n",
              "1  finding lack post alarming sex boring position...  ENTP\n",
              "2  good one course say know blessing curse absolu...  INTP\n",
              "3  dear intp enjoyed conversation day esoteric ga...  INTJ\n",
              "4  fired another silly misconception approaching ...  ENTJ"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7ab5248-d12e-4854-8476-2c2239316905\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_post</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>intj moment sportscenter top ten play prank li...</td>\n",
              "      <td>INFJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>finding lack post alarming sex boring position...</td>\n",
              "      <td>ENTP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>good one course say know blessing curse absolu...</td>\n",
              "      <td>INTP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dear intp enjoyed conversation day esoteric ga...</td>\n",
              "      <td>INTJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fired another silly misconception approaching ...</td>\n",
              "      <td>ENTJ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7ab5248-d12e-4854-8476-2c2239316905')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7ab5248-d12e-4854-8476-2c2239316905 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7ab5248-d12e-4854-8476-2c2239316905');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "training_data = data[[\"cleaned_post\", \"type\"]].copy()\n",
        "training_data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jU3qwHG9_tf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = training_data[[\"cleaned_post\"]]\n",
        "y = training_data[[\"type\"]]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKsqgXfe4eFM"
      },
      "outputs": [],
      "source": [
        "def divide_types(df):\n",
        "    df[\"E-I\"] = \"\"\n",
        "    df[\"N-S\"] = \"\"\n",
        "    df[\"F-T\"] = \"\"\n",
        "    df[\"J-P\"] = \"\"\n",
        "    for index, row in df.iterrows():\n",
        "        row[\"E-I\"] = \"E\" if row.type[0] == \"E\" else \"I\"\n",
        "        row[\"N-S\"] = \"N\" if row.type[1] == \"N\" else \"S\"\n",
        "        row[\"F-T\"] = \"F\" if row.type[2] == \"F\" else \"T\"\n",
        "        row[\"J-P\"] = \"J\" if row.type[3] == \"J\" else \"P\"\n",
        "    return df\n",
        "\n",
        "y_train = divide_types(y_train)\n",
        "y_test = divide_types(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B29Yb454uM0n"
      },
      "outputs": [],
      "source": [
        "def make_dummies(data, columns=[\"E-I\", \"N-S\", \"F-T\", \"J-P\"]):\n",
        "    for column in columns:\n",
        "        temp_dummy = pd.get_dummies(data[column], prefix=\"type\")\n",
        "        a = \"type_\" + column[2]\n",
        "        b = \"type_\" + column[0]\n",
        "        del temp_dummy[a]\n",
        "        # print(temp_dummy)\n",
        "        data = data.join(temp_dummy)\n",
        "    return data\n",
        "y_train = make_dummies(y_train)\n",
        "y_test = make_dummies(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "36LWZYel6M8T",
        "outputId": "b9bb1db9-20d3-443f-e8a0-ba60b9ff709b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      type E-I N-S F-T J-P  type_E  type_N  type_F  type_J\n",
              "4080  INFJ   I   N   F   J       0       1       1       1\n",
              "2614  ENFP   E   N   F   P       1       1       1       0\n",
              "5414  ENTP   E   N   T   P       1       1       0       0\n",
              "1039  ENFP   E   N   F   P       1       1       1       0\n",
              "8294  ENTP   E   N   T   P       1       1       0       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94021f72-6aaa-4091-8744-3422f3b4bdb5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>E-I</th>\n",
              "      <th>N-S</th>\n",
              "      <th>F-T</th>\n",
              "      <th>J-P</th>\n",
              "      <th>type_E</th>\n",
              "      <th>type_N</th>\n",
              "      <th>type_F</th>\n",
              "      <th>type_J</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4080</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>J</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2614</th>\n",
              "      <td>ENFP</td>\n",
              "      <td>E</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5414</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>E</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1039</th>\n",
              "      <td>ENFP</td>\n",
              "      <td>E</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8294</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>E</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94021f72-6aaa-4091-8744-3422f3b4bdb5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94021f72-6aaa-4091-8744-3422f3b4bdb5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94021f72-6aaa-4091-8744-3422f3b4bdb5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxzLsL4ouXaT"
      },
      "outputs": [],
      "source": [
        "X = X_train[[\"cleaned_post\"]]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "4bSfsuoNFwJV",
        "outputId": "ef2fad59-e928-433c-afd6-fdf4d222d21c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      type E-I N-S F-T J-P  type_E  type_N  type_F  type_J\n",
              "4080  INFJ   I   N   F   J       0       1       1       1\n",
              "2614  ENFP   E   N   F   P       1       1       1       0\n",
              "5414  ENTP   E   N   T   P       1       1       0       0\n",
              "1039  ENFP   E   N   F   P       1       1       1       0\n",
              "8294  ENTP   E   N   T   P       1       1       0       0\n",
              "...    ...  ..  ..  ..  ..     ...     ...     ...     ...\n",
              "5734  INFP   I   N   F   P       0       1       1       0\n",
              "5191  INFP   I   N   F   P       0       1       1       0\n",
              "5390  INFJ   I   N   F   J       0       1       1       1\n",
              "860   INFP   I   N   F   P       0       1       1       0\n",
              "7270  INTJ   I   N   T   J       0       1       0       1\n",
              "\n",
              "[6940 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c9cfc0d-c836-4b4d-861f-9738c7deedde\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>E-I</th>\n",
              "      <th>N-S</th>\n",
              "      <th>F-T</th>\n",
              "      <th>J-P</th>\n",
              "      <th>type_E</th>\n",
              "      <th>type_N</th>\n",
              "      <th>type_F</th>\n",
              "      <th>type_J</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4080</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>J</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2614</th>\n",
              "      <td>ENFP</td>\n",
              "      <td>E</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5414</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>E</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1039</th>\n",
              "      <td>ENFP</td>\n",
              "      <td>E</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8294</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>E</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5734</th>\n",
              "      <td>INFP</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>P</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5191</th>\n",
              "      <td>INFP</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>P</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5390</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>J</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>INFP</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>P</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7270</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>J</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6940 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c9cfc0d-c836-4b4d-861f-9738c7deedde')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c9cfc0d-c836-4b4d-861f-9738c7deedde button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c9cfc0d-c836-4b4d-861f-9738c7deedde');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IY_Deqaz7By"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "oversample = RandomOverSampler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rz57ACRdvIOs"
      },
      "outputs": [],
      "source": [
        "y_ei = y_train[[\"type_E\"]]\n",
        "y_ns = y_train[[\"type_N\"]]\n",
        "y_ft = y_train[[\"type_F\"]]\n",
        "y_jp = y_train[[\"type_J\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfD-v25nA1qh"
      },
      "outputs": [],
      "source": [
        "X_over_ei, y_over_ei = oversample.fit_resample(X, y_ei)\n",
        "X_over_ns, y_over_ns = oversample.fit_resample(X, y_ns)\n",
        "X_over_ft, y_over_ft = oversample.fit_resample(X, y_ft)\n",
        "X_over_jp, y_over_jp = oversample.fit_resample(X, y_jp)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QDGHdFQloOW7",
        "outputId": "3daad0e2-06d7-4b1b-afae-556605004104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           cleaned_post\n",
              "4080  loved light see anthony doerr pretty recent bo...\n",
              "2614  depends care fight get really aggressive thing...\n",
              "5414  welcome home sonny laughing strong tendency to...\n",
              "1039  really cool like anyone anything help others g...\n",
              "8294  duck named zeus see trait mammalian predator u...\n",
              "...                                                 ...\n",
              "5734  cat chihuahua pug mix really hard say prefer k...\n",
              "5191  ever since remember suffered lived anxiety nev...\n",
              "5390  known couple infj guy seem lack better term ea...\n",
              "860   even loner get lonely feel like hard hard rela...\n",
              "7270  reading response thread would said yes seem de...\n",
              "\n",
              "[6940 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10d43e41-a487-4608-9873-8ef122e4c0ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_post</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4080</th>\n",
              "      <td>loved light see anthony doerr pretty recent bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2614</th>\n",
              "      <td>depends care fight get really aggressive thing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5414</th>\n",
              "      <td>welcome home sonny laughing strong tendency to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1039</th>\n",
              "      <td>really cool like anyone anything help others g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8294</th>\n",
              "      <td>duck named zeus see trait mammalian predator u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5734</th>\n",
              "      <td>cat chihuahua pug mix really hard say prefer k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5191</th>\n",
              "      <td>ever since remember suffered lived anxiety nev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5390</th>\n",
              "      <td>known couple infj guy seem lack better term ea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>even loner get lonely feel like hard hard rela...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7270</th>\n",
              "      <td>reading response thread would said yes seem de...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6940 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10d43e41-a487-4608-9873-8ef122e4c0ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10d43e41-a487-4608-9873-8ef122e4c0ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10d43e41-a487-4608-9873-8ef122e4c0ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Eo3pxZcaM84n",
        "outputId": "f9a36e13-9ee0-47d1-fed4-c161d62deee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      type E-I N-S F-T J-P  type_E  type_N  type_F  type_J\n",
              "2802  INTP   I   N   T   P       0       1       0       0\n",
              "2166  INTJ   I   N   T   J       0       1       0       1\n",
              "1919  INTP   I   N   T   P       0       1       0       0\n",
              "360   ENFP   E   N   F   P       1       1       1       0\n",
              "1115  ENTJ   E   N   T   J       1       1       0       1\n",
              "...    ...  ..  ..  ..  ..     ...     ...     ...     ...\n",
              "7023  ISFJ   I   S   F   J       0       0       1       1\n",
              "6696  INTP   I   N   T   P       0       1       0       0\n",
              "6746  INFJ   I   N   F   J       0       1       1       1\n",
              "7966  ISTJ   I   S   T   J       0       0       0       1\n",
              "6515  INTP   I   N   T   P       0       1       0       0\n",
              "\n",
              "[1735 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5db9cd3b-8a62-497b-92d6-32eb9da7f921\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>E-I</th>\n",
              "      <th>N-S</th>\n",
              "      <th>F-T</th>\n",
              "      <th>J-P</th>\n",
              "      <th>type_E</th>\n",
              "      <th>type_N</th>\n",
              "      <th>type_F</th>\n",
              "      <th>type_J</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2802</th>\n",
              "      <td>INTP</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>P</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2166</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>J</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1919</th>\n",
              "      <td>INTP</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>P</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>ENFP</td>\n",
              "      <td>E</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1115</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>E</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>J</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7023</th>\n",
              "      <td>ISFJ</td>\n",
              "      <td>I</td>\n",
              "      <td>S</td>\n",
              "      <td>F</td>\n",
              "      <td>J</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6696</th>\n",
              "      <td>INTP</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>P</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6746</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>J</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7966</th>\n",
              "      <td>ISTJ</td>\n",
              "      <td>I</td>\n",
              "      <td>S</td>\n",
              "      <td>T</td>\n",
              "      <td>J</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6515</th>\n",
              "      <td>INTP</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>P</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1735 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5db9cd3b-8a62-497b-92d6-32eb9da7f921')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5db9cd3b-8a62-497b-92d6-32eb9da7f921 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5db9cd3b-8a62-497b-92d6-32eb9da7f921');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/mbti_1.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "q7Kdht5faB-1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7c2c0cf5-2160-43b3-a41f-a7ed74fbb366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   type                                              posts\n",
              "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
              "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
              "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
              "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
              "4  ENTJ  'You're fired.|||That's another silly misconce..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b95cfc5-12b0-4285-9c75-deadd6d56281\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>INTP</td>\n",
              "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>'You're fired.|||That's another silly misconce...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b95cfc5-12b0-4285-9c75-deadd6d56281')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b95cfc5-12b0-4285-9c75-deadd6d56281 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b95cfc5-12b0-4285-9c75-deadd6d56281');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7FbTexy4npp"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import GRU\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVMyj0IzY3IJ",
        "outputId": "998e60d4-d7ef-4b7b-d08f-95e5b75ac387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-21 06:59:42--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-04-21 06:59:42--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-04-21 06:59:43--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2023-04-21 07:02:22 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NSQEt4TwIqR"
      },
      "outputs": [],
      "source": [
        "def loadData_Tokenizer(X_train, X_test,MAX_NB_WORDS=75000,MAX_SEQUENCE_LENGTH=500):\n",
        "    np.random.seed(7)\n",
        "    text = np.concatenate((X_train, X_test), axis=0)\n",
        "    text = np.array(text)\n",
        "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    sequences = tokenizer.texts_to_sequences(text)\n",
        "    word_index = tokenizer.word_index\n",
        "    text = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    print('Found %s unique tokens.' % len(word_index))\n",
        "    indices = np.arange(text.shape[0])\n",
        "    # np.random.shuffle(indices)\n",
        "    text = text[indices]\n",
        "    print(text.shape)\n",
        "    X_train = text[0:len(X_train), ]\n",
        "    X_test = text[len(X_train):, ]\n",
        "    embeddings_index = {}\n",
        "    f = open(\"glove.6B.50d.txt\", encoding=\"utf8\")\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        try:\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "        except:\n",
        "            pass\n",
        "        embeddings_index[word] = coefs\n",
        "    f.close()\n",
        "    print('Total %s word vectors.' % len(embeddings_index))\n",
        "    return (X_train, X_test, word_index,embeddings_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-bMVe6KwTpb"
      },
      "outputs": [],
      "source": [
        "from keras.layers import LSTM\n",
        "def Build_Model_RCNN_Text(word_index, embeddings_index, nclasses, MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=50):\n",
        "\n",
        "    kernel_size = 2\n",
        "    filters = 256\n",
        "    pool_size = 2\n",
        "    gru_node = 256\n",
        "\n",
        "    embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            if len(embedding_matrix[i]) !=len(embedding_vector):\n",
        "                print(\"could not broadcast input array from shape\",str(len(embedding_matrix[i])),\n",
        "                                 \"into shape\",str(len(embedding_vector)),\" Please make sure your\"\n",
        "                                 \" EMBEDDING_DIM is equal to embedding_vector file ,GloVe,\")\n",
        "                exit(1)\n",
        "\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(word_index) + 1,\n",
        "                                EMBEDDING_DIM,\n",
        "                                weights=[embedding_matrix],\n",
        "                                input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                trainable=True))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=pool_size))\n",
        "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=pool_size))\n",
        "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=pool_size))\n",
        "    model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=pool_size))\n",
        "    model.add(LSTM(gru_node, return_sequences=True, recurrent_dropout=0.2))\n",
        "    model.add(LSTM(gru_node, return_sequences=True, recurrent_dropout=0.2))\n",
        "    model.add(LSTM(gru_node, return_sequences=True, recurrent_dropout=0.2))\n",
        "    model.add(LSTM(gru_node, recurrent_dropout=0.2))\n",
        "    model.add(Dense(1024,activation='relu'))\n",
        "    model.add(Dense(nclasses))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5jpTvgHwbfv",
        "outputId": "f5858710-848b-4a86-fdf2-26c61ea5f85e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 87613 unique tokens.\n",
            "(8675, 500)\n",
            "Total 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "X_train_ei = X.cleaned_post.values\n",
        "y_train_ei = y_ei.type_E.values\n",
        "X_test_ei = X_test.cleaned_post.values\n",
        "y_test_ei = y_test.type_E.values\n",
        "X_train_Glove,X_test_Glove, word_index,embeddings_index = loadData_Tokenizer((X_train_ei.tolist()),(X_test_ei.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1O3Ues-w77w",
        "outputId": "bc5b0144-1252-4407-8c39-1461caa42cae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 500, 50)           4380700   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 500, 50)           0         \n",
            "                                                                 \n",
            " conv1d_8 (Conv1D)           (None, 499, 256)          25856     \n",
            "                                                                 \n",
            " max_pooling1d_8 (MaxPooling  (None, 249, 256)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 248, 256)          131328    \n",
            "                                                                 \n",
            " max_pooling1d_9 (MaxPooling  (None, 124, 256)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_10 (Conv1D)          (None, 123, 256)          131328    \n",
            "                                                                 \n",
            " max_pooling1d_10 (MaxPoolin  (None, 61, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_11 (Conv1D)          (None, 60, 256)           131328    \n",
            "                                                                 \n",
            " max_pooling1d_11 (MaxPoolin  (None, 30, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 256)               525312    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1024)              263168    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 2050      \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,167,006\n",
            "Trainable params: 7,167,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "55/55 - 96s - loss: 0.5552 - accuracy: 0.7575 - val_loss: 0.5371 - val_accuracy: 0.7798 - 96s/epoch - 2s/step\n",
            "Epoch 2/15\n",
            "55/55 - 61s - loss: 0.5449 - accuracy: 0.7670 - val_loss: 0.5276 - val_accuracy: 0.7798 - 61s/epoch - 1s/step\n",
            "Epoch 3/15\n",
            "55/55 - 57s - loss: 0.5454 - accuracy: 0.7670 - val_loss: 0.5283 - val_accuracy: 0.7798 - 57s/epoch - 1s/step\n",
            "Epoch 4/15\n",
            "55/55 - 69s - loss: 0.5450 - accuracy: 0.7670 - val_loss: 0.5271 - val_accuracy: 0.7798 - 69s/epoch - 1s/step\n",
            "Epoch 5/15\n",
            "55/55 - 74s - loss: 0.5464 - accuracy: 0.7670 - val_loss: 0.5282 - val_accuracy: 0.7798 - 74s/epoch - 1s/step\n",
            "Epoch 6/15\n",
            "55/55 - 51s - loss: 0.5437 - accuracy: 0.7670 - val_loss: 0.5286 - val_accuracy: 0.7798 - 51s/epoch - 925ms/step\n",
            "Epoch 7/15\n",
            "55/55 - 56s - loss: 0.5432 - accuracy: 0.7670 - val_loss: 0.5278 - val_accuracy: 0.7798 - 56s/epoch - 1s/step\n",
            "Epoch 8/15\n",
            "55/55 - 38s - loss: 0.5451 - accuracy: 0.7670 - val_loss: 0.5286 - val_accuracy: 0.7798 - 38s/epoch - 688ms/step\n",
            "Epoch 9/15\n",
            "55/55 - 38s - loss: 0.5440 - accuracy: 0.7670 - val_loss: 0.5271 - val_accuracy: 0.7798 - 38s/epoch - 685ms/step\n",
            "Epoch 10/15\n",
            "55/55 - 36s - loss: 0.5444 - accuracy: 0.7670 - val_loss: 0.5278 - val_accuracy: 0.7798 - 36s/epoch - 650ms/step\n",
            "Epoch 11/15\n",
            "55/55 - 46s - loss: 0.5454 - accuracy: 0.7670 - val_loss: 0.5276 - val_accuracy: 0.7798 - 46s/epoch - 841ms/step\n",
            "Epoch 12/15\n",
            "55/55 - 39s - loss: 0.5438 - accuracy: 0.7670 - val_loss: 0.5278 - val_accuracy: 0.7798 - 39s/epoch - 705ms/step\n",
            "Epoch 13/15\n",
            "55/55 - 38s - loss: 0.5441 - accuracy: 0.7670 - val_loss: 0.5319 - val_accuracy: 0.7798 - 38s/epoch - 685ms/step\n",
            "Epoch 14/15\n",
            "55/55 - 35s - loss: 0.5437 - accuracy: 0.7670 - val_loss: 0.5303 - val_accuracy: 0.7798 - 35s/epoch - 639ms/step\n",
            "Epoch 15/15\n",
            "55/55 - 36s - loss: 0.5430 - accuracy: 0.7670 - val_loss: 0.5273 - val_accuracy: 0.7798 - 36s/epoch - 661ms/step\n",
            "55/55 [==============================] - 3s 42ms/step\n",
            "Without oversample ei\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      1.00      0.88      1353\n",
            "           1       0.00      0.00      0.00       382\n",
            "\n",
            "    accuracy                           0.78      1735\n",
            "   macro avg       0.39      0.50      0.44      1735\n",
            "weighted avg       0.61      0.78      0.68      1735\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "model_RCNN = Build_Model_RCNN_Text(word_index,embeddings_index, 2)\n",
        "\n",
        "\n",
        "model_RCNN.summary()\n",
        "\n",
        "model_RCNN.fit(X_train_Glove, y_train_ei,\n",
        "                              validation_data=(X_test_Glove, y_test_ei),\n",
        "                              epochs=15,\n",
        "                              batch_size=128,\n",
        "                              verbose=2)\n",
        "\n",
        "predicted_wei = model_RCNN.predict(X_test_Glove)\n",
        "\n",
        "predicted_wei = np.argmax(predicted_wei, axis=1)\n",
        "print(\"Without oversample ei\")\n",
        "print(metrics.classification_report(y_test_ei, predicted_wei))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggOf4kbPxB_b",
        "outputId": "650e32bd-2dfc-4e72-f8fa-aebc84d1e2fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "0.7798270893371758\n",
            "0.0\n",
            "0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(metrics.f1_score(y_test_ei, predicted_wei))\n",
        "print(metrics.accuracy_score(y_test_ei, predicted_wei))\n",
        "print(metrics.precision_score(y_test_ei, predicted_wei))\n",
        "print(metrics.recall_score(y_test_ei, predicted_wei))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfSw1j2YJz7S",
        "outputId": "724aad4b-9709-4d48-b71d-6f45e0b659ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 87613 unique tokens.\n",
            "(8675, 500)\n",
            "Total 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "X_train_jp = X.cleaned_post.values\n",
        "y_train_jp = y_jp.type_J.values\n",
        "X_test_jp = X_test.cleaned_post.values\n",
        "y_test_jp = y_test.type_J.values\n",
        "X_train_Glove,X_test_Glove, word_index,embeddings_index = loadData_Tokenizer((X_train_jp.tolist()),(X_test_jp.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89Ae6ocIKjMu",
        "outputId": "f21e7cba-bf56-4964-b1bd-b19c9897e39e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 500, 50)           4380700   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 500, 50)           0         \n",
            "                                                                 \n",
            " conv1d_12 (Conv1D)          (None, 499, 256)          25856     \n",
            "                                                                 \n",
            " max_pooling1d_12 (MaxPoolin  (None, 249, 256)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_13 (Conv1D)          (None, 248, 256)          131328    \n",
            "                                                                 \n",
            " max_pooling1d_13 (MaxPoolin  (None, 124, 256)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_14 (Conv1D)          (None, 123, 256)          131328    \n",
            "                                                                 \n",
            " max_pooling1d_14 (MaxPoolin  (None, 61, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_15 (Conv1D)          (None, 60, 256)           131328    \n",
            "                                                                 \n",
            " max_pooling1d_15 (MaxPoolin  (None, 30, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " lstm_12 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_13 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_14 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_15 (LSTM)              (None, 256)               525312    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1024)              263168    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 2050      \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,167,006\n",
            "Trainable params: 7,167,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "55/55 - 57s - loss: 0.6796 - accuracy: 0.5922 - val_loss: 0.6716 - val_accuracy: 0.6144 - 57s/epoch - 1s/step\n",
            "Epoch 2/15\n",
            "55/55 - 40s - loss: 0.6720 - accuracy: 0.6016 - val_loss: 0.6601 - val_accuracy: 0.6144 - 40s/epoch - 730ms/step\n",
            "Epoch 3/15\n",
            "55/55 - 39s - loss: 0.6736 - accuracy: 0.5965 - val_loss: 0.6647 - val_accuracy: 0.6144 - 39s/epoch - 716ms/step\n",
            "Epoch 4/15\n",
            "55/55 - 37s - loss: 0.6691 - accuracy: 0.6052 - val_loss: 0.6573 - val_accuracy: 0.6144 - 37s/epoch - 679ms/step\n",
            "Epoch 5/15\n",
            "55/55 - 38s - loss: 0.6260 - accuracy: 0.6527 - val_loss: 0.8212 - val_accuracy: 0.5712 - 38s/epoch - 695ms/step\n",
            "Epoch 6/15\n",
            "55/55 - 38s - loss: 0.6019 - accuracy: 0.6849 - val_loss: 0.6006 - val_accuracy: 0.6968 - 38s/epoch - 694ms/step\n",
            "Epoch 7/15\n",
            "55/55 - 37s - loss: 0.4552 - accuracy: 0.8016 - val_loss: 0.4867 - val_accuracy: 0.7821 - 37s/epoch - 679ms/step\n",
            "Epoch 8/15\n",
            "55/55 - 36s - loss: 0.3792 - accuracy: 0.8392 - val_loss: 0.4505 - val_accuracy: 0.7914 - 36s/epoch - 648ms/step\n",
            "Epoch 9/15\n",
            "55/55 - 36s - loss: 0.3269 - accuracy: 0.8669 - val_loss: 0.5191 - val_accuracy: 0.7677 - 36s/epoch - 663ms/step\n",
            "Epoch 10/15\n",
            "55/55 - 34s - loss: 0.2667 - accuracy: 0.8960 - val_loss: 0.5882 - val_accuracy: 0.7729 - 34s/epoch - 626ms/step\n",
            "Epoch 11/15\n",
            "55/55 - 36s - loss: 0.2437 - accuracy: 0.9056 - val_loss: 0.5454 - val_accuracy: 0.7960 - 36s/epoch - 661ms/step\n",
            "Epoch 12/15\n",
            "55/55 - 33s - loss: 0.1933 - accuracy: 0.9301 - val_loss: 0.6383 - val_accuracy: 0.7527 - 33s/epoch - 600ms/step\n",
            "Epoch 13/15\n",
            "55/55 - 35s - loss: 0.1582 - accuracy: 0.9419 - val_loss: 0.7246 - val_accuracy: 0.7729 - 35s/epoch - 641ms/step\n",
            "Epoch 14/15\n",
            "55/55 - 32s - loss: 0.1418 - accuracy: 0.9474 - val_loss: 0.7771 - val_accuracy: 0.7648 - 32s/epoch - 589ms/step\n",
            "Epoch 15/15\n",
            "55/55 - 34s - loss: 0.1012 - accuracy: 0.9666 - val_loss: 0.7279 - val_accuracy: 0.7695 - 34s/epoch - 625ms/step\n",
            "55/55 [==============================] - 3s 39ms/step\n",
            "Without oversample jp\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.84      0.82      1066\n",
            "           1       0.72      0.66      0.69       669\n",
            "\n",
            "    accuracy                           0.77      1735\n",
            "   macro avg       0.76      0.75      0.75      1735\n",
            "weighted avg       0.77      0.77      0.77      1735\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_RCNN = Build_Model_RCNN_Text(word_index,embeddings_index, 2)\n",
        "\n",
        "\n",
        "model_RCNN.summary()\n",
        "\n",
        "model_RCNN.fit(X_train_Glove, y_train_jp,\n",
        "                              validation_data=(X_test_Glove, y_test_jp),\n",
        "                              epochs=15,\n",
        "                              batch_size=128,\n",
        "                              verbose=2)\n",
        "\n",
        "predicted_wjp = model_RCNN.predict(X_test_Glove)\n",
        "\n",
        "predicted_wjp = np.argmax(predicted_wjp, axis=1)\n",
        "print(\"Without oversample jp\")\n",
        "print(metrics.classification_report(y_test_jp, predicted_wjp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k0iFrU3K0CD",
        "outputId": "f5a64a54-803e-454a-bce9-fe88644f3ced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6889580093312597\n",
            "0.7694524495677233\n",
            "0.7179902755267423\n",
            "0.6621823617339312\n"
          ]
        }
      ],
      "source": [
        "print(metrics.f1_score(y_test_jp, predicted_wjp))\n",
        "print(metrics.accuracy_score(y_test_jp, predicted_wjp))\n",
        "print(metrics.precision_score(y_test_jp, predicted_wjp))\n",
        "print(metrics.recall_score(y_test_jp, predicted_wjp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCLB4uhhOo_v",
        "outputId": "1addab64-0097-4cc7-f858-ee9c65f87e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 87613 unique tokens.\n",
            "(8675, 500)\n",
            "Total 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "X_train_ft = X.cleaned_post.values\n",
        "y_train_ft = y_ft.type_F.values\n",
        "X_test_ft = X_test.cleaned_post.values\n",
        "y_test_ft = y_test.type_F.values\n",
        "X_train_Glove,X_test_Glove, word_index,embeddings_index = loadData_Tokenizer((X_train_ft.tolist()),(X_test_ft.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNl1iViWP4KD",
        "outputId": "a16f99ff-805a-463c-a0cc-865f36a3b6b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 500, 50)           4380700   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 500, 50)           0         \n",
            "                                                                 \n",
            " conv1d_16 (Conv1D)          (None, 499, 256)          25856     \n",
            "                                                                 \n",
            " max_pooling1d_16 (MaxPoolin  (None, 249, 256)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_17 (Conv1D)          (None, 248, 256)          131328    \n",
            "                                                                 \n",
            " max_pooling1d_17 (MaxPoolin  (None, 124, 256)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_18 (Conv1D)          (None, 123, 256)          131328    \n",
            "                                                                 \n",
            " max_pooling1d_18 (MaxPoolin  (None, 61, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_19 (Conv1D)          (None, 60, 256)           131328    \n",
            "                                                                 \n",
            " max_pooling1d_19 (MaxPoolin  (None, 30, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " lstm_16 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_17 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_18 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_19 (LSTM)              (None, 256)               525312    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1024)              263168    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 2)                 2050      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,167,006\n",
            "Trainable params: 7,167,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "55/55 - 55s - loss: 0.6932 - accuracy: 0.5359 - val_loss: 0.6625 - val_accuracy: 0.5654 - 55s/epoch - 1s/step\n",
            "Epoch 2/15\n",
            "55/55 - 40s - loss: 0.6567 - accuracy: 0.6095 - val_loss: 0.6276 - val_accuracy: 0.6444 - 40s/epoch - 736ms/step\n",
            "Epoch 3/15\n",
            "55/55 - 38s - loss: 0.5750 - accuracy: 0.7197 - val_loss: 0.5986 - val_accuracy: 0.7383 - 38s/epoch - 686ms/step\n",
            "Epoch 4/15\n",
            "55/55 - 37s - loss: 0.4942 - accuracy: 0.7674 - val_loss: 0.4379 - val_accuracy: 0.8023 - 37s/epoch - 679ms/step\n",
            "Epoch 5/15\n",
            "55/55 - 38s - loss: 0.3915 - accuracy: 0.8333 - val_loss: 0.4038 - val_accuracy: 0.8323 - 38s/epoch - 683ms/step\n",
            "Epoch 6/15\n",
            "55/55 - 35s - loss: 0.3253 - accuracy: 0.8715 - val_loss: 0.3912 - val_accuracy: 0.8317 - 35s/epoch - 638ms/step\n",
            "Epoch 7/15\n",
            "55/55 - 35s - loss: 0.2766 - accuracy: 0.8961 - val_loss: 0.4151 - val_accuracy: 0.8311 - 35s/epoch - 641ms/step\n",
            "Epoch 8/15\n",
            "55/55 - 35s - loss: 0.2639 - accuracy: 0.9037 - val_loss: 0.4536 - val_accuracy: 0.8231 - 35s/epoch - 630ms/step\n",
            "Epoch 9/15\n",
            "55/55 - 35s - loss: 0.1881 - accuracy: 0.9313 - val_loss: 0.4879 - val_accuracy: 0.8190 - 35s/epoch - 631ms/step\n",
            "Epoch 10/15\n",
            "55/55 - 34s - loss: 0.1647 - accuracy: 0.9427 - val_loss: 0.4961 - val_accuracy: 0.8305 - 34s/epoch - 621ms/step\n",
            "Epoch 11/15\n",
            "55/55 - 33s - loss: 0.1312 - accuracy: 0.9562 - val_loss: 0.5399 - val_accuracy: 0.8156 - 33s/epoch - 596ms/step\n",
            "Epoch 12/15\n",
            "55/55 - 32s - loss: 0.1182 - accuracy: 0.9610 - val_loss: 0.5420 - val_accuracy: 0.8219 - 32s/epoch - 590ms/step\n",
            "Epoch 13/15\n",
            "55/55 - 32s - loss: 0.1131 - accuracy: 0.9620 - val_loss: 0.5653 - val_accuracy: 0.8231 - 32s/epoch - 585ms/step\n",
            "Epoch 14/15\n",
            "55/55 - 32s - loss: 0.0714 - accuracy: 0.9772 - val_loss: 0.7477 - val_accuracy: 0.7988 - 32s/epoch - 583ms/step\n",
            "Epoch 15/15\n",
            "55/55 - 30s - loss: 0.0819 - accuracy: 0.9728 - val_loss: 0.6587 - val_accuracy: 0.8121 - 30s/epoch - 546ms/step\n",
            "55/55 [==============================] - 3s 36ms/step\n",
            "Without oversample ft\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.76      0.79       798\n",
            "           1       0.81      0.85      0.83       937\n",
            "\n",
            "    accuracy                           0.81      1735\n",
            "   macro avg       0.81      0.81      0.81      1735\n",
            "weighted avg       0.81      0.81      0.81      1735\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_RCNN = Build_Model_RCNN_Text(word_index,embeddings_index, 2)\n",
        "\n",
        "\n",
        "model_RCNN.summary()\n",
        "\n",
        "model_RCNN.fit(X_train_Glove, y_train_ft,\n",
        "                              validation_data=(X_test_Glove, y_test_ft),\n",
        "                              epochs=15,\n",
        "                              batch_size=128,\n",
        "                              verbose=2)\n",
        "\n",
        "predicted_wft = model_RCNN.predict(X_test_Glove)\n",
        "\n",
        "predicted_wft = np.argmax(predicted_wft, axis=1)\n",
        "print(\"Without oversample ft\")\n",
        "print(metrics.classification_report(y_test_ft, predicted_wft))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiqkDWx0QAPW",
        "outputId": "ca3c64b9-9b70-43ef-83a5-cd853f600072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8305613305613305\n",
            "0.8121037463976946\n",
            "0.8095238095238095\n",
            "0.8527214514407684\n"
          ]
        }
      ],
      "source": [
        "print(metrics.f1_score(y_test_ft, predicted_wft))\n",
        "print(metrics.accuracy_score(y_test_ft, predicted_wft))\n",
        "print(metrics.precision_score(y_test_ft, predicted_wft))\n",
        "print(metrics.recall_score(y_test_ft, predicted_wft))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXQj4gBnSNYf",
        "outputId": "6ce8ecd1-0fff-403c-f1c8-356639233cbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 87613 unique tokens.\n",
            "(8675, 500)\n",
            "Total 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "X_train_ns = X.cleaned_post.values\n",
        "y_train_ns = y_ns.type_N.values\n",
        "X_test_ns = X_test.cleaned_post.values\n",
        "y_test_ns = y_test.type_N.values\n",
        "X_train_Glove,X_test_Glove, word_index,embeddings_index = loadData_Tokenizer((X_train_ns.tolist()),(X_test_ns.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zn-dbk5kWiJ2",
        "outputId": "1fc6f374-abab-4423-bf66-ae9631b47dc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 500, 50)           4380700   \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 500, 50)           0         \n",
            "                                                                 \n",
            " conv1d_20 (Conv1D)          (None, 499, 256)          25856     \n",
            "                                                                 \n",
            " max_pooling1d_20 (MaxPoolin  (None, 249, 256)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_21 (Conv1D)          (None, 248, 256)          131328    \n",
            "                                                                 \n",
            " max_pooling1d_21 (MaxPoolin  (None, 124, 256)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_22 (Conv1D)          (None, 123, 256)          131328    \n",
            "                                                                 \n",
            " max_pooling1d_22 (MaxPoolin  (None, 61, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_23 (Conv1D)          (None, 60, 256)           131328    \n",
            "                                                                 \n",
            " max_pooling1d_23 (MaxPoolin  (None, 30, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " lstm_20 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_21 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_22 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_23 (LSTM)              (None, 256)               525312    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1024)              263168    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 2)                 2050      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,167,006\n",
            "Trainable params: 7,167,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "55/55 - 49s - loss: 0.4155 - accuracy: 0.8630 - val_loss: 0.4101 - val_accuracy: 0.8582 - 49s/epoch - 886ms/step\n",
            "Epoch 2/15\n",
            "55/55 - 34s - loss: 0.4032 - accuracy: 0.8630 - val_loss: 0.4127 - val_accuracy: 0.8582 - 34s/epoch - 614ms/step\n",
            "Epoch 3/15\n",
            "55/55 - 34s - loss: 0.4005 - accuracy: 0.8630 - val_loss: 0.4095 - val_accuracy: 0.8582 - 34s/epoch - 626ms/step\n",
            "Epoch 4/15\n",
            "55/55 - 32s - loss: 0.4024 - accuracy: 0.8630 - val_loss: 0.4082 - val_accuracy: 0.8582 - 32s/epoch - 589ms/step\n",
            "Epoch 5/15\n",
            "55/55 - 32s - loss: 0.4023 - accuracy: 0.8630 - val_loss: 0.4104 - val_accuracy: 0.8582 - 32s/epoch - 584ms/step\n",
            "Epoch 6/15\n",
            "55/55 - 32s - loss: 0.4042 - accuracy: 0.8630 - val_loss: 0.4119 - val_accuracy: 0.8582 - 32s/epoch - 581ms/step\n",
            "Epoch 7/15\n",
            "55/55 - 32s - loss: 0.4013 - accuracy: 0.8630 - val_loss: 0.4084 - val_accuracy: 0.8582 - 32s/epoch - 589ms/step\n",
            "Epoch 8/15\n",
            "55/55 - 34s - loss: 0.4001 - accuracy: 0.8630 - val_loss: 0.4098 - val_accuracy: 0.8582 - 34s/epoch - 626ms/step\n",
            "Epoch 9/15\n",
            "55/55 - 31s - loss: 0.4003 - accuracy: 0.8630 - val_loss: 0.4098 - val_accuracy: 0.8582 - 31s/epoch - 562ms/step\n",
            "Epoch 10/15\n",
            "55/55 - 32s - loss: 0.4011 - accuracy: 0.8630 - val_loss: 0.4097 - val_accuracy: 0.8582 - 32s/epoch - 579ms/step\n",
            "Epoch 11/15\n",
            "55/55 - 34s - loss: 0.4000 - accuracy: 0.8630 - val_loss: 0.4082 - val_accuracy: 0.8582 - 34s/epoch - 613ms/step\n",
            "Epoch 12/15\n",
            "55/55 - 31s - loss: 0.4002 - accuracy: 0.8630 - val_loss: 0.4083 - val_accuracy: 0.8582 - 31s/epoch - 558ms/step\n",
            "Epoch 13/15\n",
            "55/55 - 30s - loss: 0.4009 - accuracy: 0.8630 - val_loss: 0.4108 - val_accuracy: 0.8582 - 30s/epoch - 542ms/step\n",
            "Epoch 14/15\n",
            "55/55 - 31s - loss: 0.4013 - accuracy: 0.8630 - val_loss: 0.4084 - val_accuracy: 0.8582 - 31s/epoch - 565ms/step\n",
            "Epoch 15/15\n",
            "55/55 - 30s - loss: 0.4000 - accuracy: 0.8630 - val_loss: 0.4088 - val_accuracy: 0.8582 - 30s/epoch - 553ms/step\n",
            "55/55 [==============================] - 3s 35ms/step\n",
            "without oversample ns\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       246\n",
            "           1       0.86      1.00      0.92      1489\n",
            "\n",
            "    accuracy                           0.86      1735\n",
            "   macro avg       0.43      0.50      0.46      1735\n",
            "weighted avg       0.74      0.86      0.79      1735\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "model_RCNN = Build_Model_RCNN_Text(word_index,embeddings_index, 2)\n",
        "\n",
        "\n",
        "model_RCNN.summary()\n",
        "\n",
        "model_RCNN.fit(X_train_Glove, y_train_ns,\n",
        "                              validation_data=(X_test_Glove, y_test_ns),\n",
        "                              epochs=15,\n",
        "                              batch_size=128,\n",
        "                              verbose=2)\n",
        "\n",
        "predicted_wns = model_RCNN.predict(X_test_Glove)\n",
        "\n",
        "predicted_wns = np.argmax(predicted_wns, axis=1)\n",
        "print(\"without oversample ns\")\n",
        "print(metrics.classification_report(y_test_ns, predicted_wns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPGx7HINWoB0",
        "outputId": "d0fb2170-6992-4780-aa00-98e703b70a60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.923697270471464\n",
            "0.8582132564841498\n",
            "0.8582132564841498\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "print(metrics.f1_score(y_test_ns, predicted_wns))\n",
        "print(metrics.accuracy_score(y_test_ns, predicted_wns))\n",
        "print(metrics.precision_score(y_test_ns, predicted_wns))\n",
        "print(metrics.recall_score(y_test_ns, predicted_wns))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E_I = predicted_wei\n",
        "J_P = predicted_wjp\n",
        "F_T = predicted_wft\n",
        "N_S = predicted_wns"
      ],
      "metadata": {
        "id": "qqM9VLAcrmV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = []\n",
        "for i in range(len(E_I)):\n",
        "  s = \"\"\n",
        "  #enfj\n",
        "  if(E_I[i] == 0) :\n",
        "    s = s + \"I\"\n",
        "  else :\n",
        "    s = s + \"E\"\n",
        "  if (N_S[i] == 0) :\n",
        "    s = s + \"S\"\n",
        "  else:\n",
        "    s = s + \"N\"\n",
        "  if (F_T[i] == 0) :\n",
        "    s = s + \"T\"\n",
        "  else:\n",
        "    s = s + \"F\"\n",
        "  if (J_P[i] == 0) :\n",
        "    s = s + \"P\"\n",
        "  else:\n",
        "    s = s + \"J\"\n",
        "  predicted.append(s)\n",
        "print(predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjxYzO3rrpIA",
        "outputId": "49fb0577-d7c2-4920-acc2-c3bbd62b8f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['INTP', 'INFJ', 'INTP', 'INFP', 'INTJ', 'INFJ', 'INFJ', 'INTP', 'INTJ', 'INTP', 'INFP', 'INTJ', 'INFJ', 'INFP', 'INTP', 'INTP', 'INTP', 'INTP', 'INFP', 'INTJ', 'INFJ', 'INTJ', 'INTJ', 'INFP', 'INTP', 'INTJ', 'INTP', 'INTJ', 'INTP', 'INTP', 'INTJ', 'INTJ', 'INTP', 'INFP', 'INTP', 'INFP', 'INFJ', 'INFJ', 'INTP', 'INFP', 'INTJ', 'INFP', 'INTP', 'INFP', 'INFP', 'INFJ', 'INFP', 'INTP', 'INFJ', 'INTP', 'INFP', 'INTP', 'INTP', 'INFP', 'INTJ', 'INFP', 'INTP', 'INFJ', 'INFP', 'INTP', 'INTJ', 'INFP', 'INTP', 'INTP', 'INTP', 'INTP', 'INTP', 'INFP', 'INFP', 'INTP', 'INFP', 'INTP', 'INTP', 'INTP', 'INTJ', 'INFP', 'INFP', 'INTJ', 'INFP', 'INTJ', 'INTP', 'INTJ', 'INTJ', 'INFP', 'INFP', 'INTJ', 'INFJ', 'INFJ', 'INTP', 'INFP', 'INTP', 'INFP', 'INTP', 'INFP', 'INFJ', 'INTJ', 'INTP', 'INFJ', 'INFJ', 'INFP', 'INTP', 'INFJ', 'INFJ', 'INFJ', 'INTP', 'INTP', 'INTP', 'INTP', 'INTP', 'INTP', 'INFJ', 'INTJ', 'INFP', 'INFP', 'INFP', 'INFP', 'INFJ', 'INFP', 'INFJ', 'INFP', 'INFJ', 'INFP', 'INTJ', 'INTP', 'INTJ', 'INFP', 'INFP', 'INTJ', 'INTJ', 'INTP', 'INTJ', 'INFP', 'INFP', 'INFJ', 'INTP', 'INFP', 'INTP', 'INTP', 'INTP', 'INFJ', 'INFJ', 'INFP', 'INTP', 'INFJ', 'INFJ', 'INTP', 'INFP', 'INFP', 'INFP', 'INFP', 'INFP', 'INTP', 'INTP', 'INFJ', 'INTP', 'INTP', 'INTP', 'INTP', 'INFJ', 'INFP', 'INTP', 'INTP', 'INFP', 'INTP', 'INTJ', 'INFP', 'INFJ', 'INFP', 'INFP', 'INTP', 'INTJ', 'INFP', 'INFP', 'INFP', 'INFP', 'INTJ', 'INFP', 'INFJ', 'INFP', 'INFP', 'INFP', 'INTP', 'INTP', 'INTP', 'INTJ', 'INFJ', 'INFP', 'INFJ', 'INFP', 'INTP', 'INFP', 'INTJ', 'INFJ', 'INFJ', 'INFJ', 'INFJ', 'INFP', 'INFP', 'INTJ', 'INFJ', 'INFP', 'INFJ', 'INFP', 'INFP', 'INTP', 'INTP', 'INTJ', 'INFJ', 'INTP', 'INTJ', 'INTJ', 'INTP', 'INFP', 'INFP', 'INTJ', 'INFP', 'INTP', 'INTJ', 'INTP', 'INTP', 'INFJ', 'INTP', 'INFP', 'INTP', 'INTJ', 'INFP', 'INTJ', 'INFJ', 'INTP', 'INTP', 'INTJ', 'INFJ', 'INTJ', 'INFP', 'INTJ', 'INTP', 'INTP', 'INTP', 'INTJ', 'INFJ', 'INTP', 'INTP', 'INFP', 'INTP', 'INFJ', 'INFP', 'INTJ', 'INFP', 'INFP', 'INFP', 'INTP', 'INTP', 'INTP', 'INFP', 'INFP', 'INTJ', 'INTJ', 'INFP', 'INFP', 'INFP', 'INFP', 'INFP', 'INFP', 'INTP', 'INFJ', 'INTP', 'INFP', 'INTJ', 'INTP', 'INFJ', 'INTP', 'INFP', 'INFJ', 'INFJ', 'INFP', 'INFJ', 'INFP', 'INFP', 'INTJ', 'INFJ', 'INTP', 'INFP', 'INFP', 'INTJ', 'INFJ', 'INFP', 'INFP', 'INFJ', 'INFJ', 'INTJ', 'INFP', 'INFP', 'INFP', 'INTJ', 'INFJ', 'INFP', 'INTJ', 'INFP', 'INTP', 'INTP', 'INTP', 'INFJ', 'INTP', 'INFJ', 'INFJ', 'INFP', 'INFP', 'INFP', 'INFJ', 'INTP', 'INFP', 'INFJ', 'INFP', 'INFP', 'INTP', 'INFP', 'INFP', 'INTJ', 'INFJ', 'INTP', 'INFP', 'INFP', 'INFP', 'INTP', 'INFP', 'INFJ', 'INFP', 'INFP', 'INTP', 'INFP', 'INFP', 'INFP', 'INFP', 'INTP', 'INTP', 'INFP', 'INTP', 'INTP', 'INFP', 'INFP', 'INFP', 'INFJ', 'INFJ', 'INTP', 'INFP', 'INFP', 'INFJ', 'INTP', 'INFP', 'INTP', 'INTJ', 'INTJ', 'INFP', 'INFJ', 'INFP', 'INTP', 'INTJ', 'INTP', 'INTP', 'INTP', 'INFP', 'INTJ', 'INFJ', 'INFP', 'INFJ', 'INTJ', 'INFJ', 'INTP', 'INFJ', 'INFJ', 'INFP', 'INTJ', 'INFP', 'INFP', 'INFJ', 'INTP', 'INFP', 'INTJ', 'INTP', 'INFP', 'INTP', 'INTP', 'INTP', 'INTJ', 'INTP', 'INFJ', 'INFP', 'INFJ', 'INFJ', 'INFP', 'INFP', 'INFP', 'INFP', 'INTP', 'INFP', 'INTJ', 'INFP', 'INFP', 'INFJ', 'INFP', 'INTJ', 'INFJ', 'INFJ', 'INTJ', 'INTP', 'INFP', 'INTP', 'INTP', 'INFP', 'INTP', 'INTP', 'INFJ', 'INFP', 'INFJ', 'INFP', 'INTP', 'INFP', 'INFJ', 'INFP', 'INFJ', 'INFP', 'INFP', 'INFJ', 'INTP', 'INFJ', 'INFJ', 'INTJ', 'INTJ', 'INTP', 'INFJ', 'INFP', 'INTP', 'INTP', 'INTP', 'INFP', 'INTJ', 'INFJ', 'INTJ', 'INTJ', 'INTP', 'INFJ', 'INTP', 'INFP', 'INTP', 'INFP', 'INTP', 'INFJ', 'INTJ', 'INFP', 'INFP', 'INFJ', 'INTJ', 'INFP', 'INFJ', 'INTP', 'INFP', 'INTJ', 'INFP', 'INTJ', 'INTP', 'INFP', 'INFP', 'INTJ', 'INFP', 'INTP', 'INFP', 'INFP', 'INTP', 'INFP', 'INFP', 'INFJ', 'INFP', 'INTJ', 'INFP', 'INFP', 'INFP', 'INFP', 'INTP', 'INTP', 'INFP', 'INFJ', 'INFJ', 'INFP', 'INFP', 'INTP', 'INFP', 'INFJ', 'INFP', 'INFP', 'INTP', 'INFP', 'INTP', 'INTJ', 'INFJ', 'INFJ', 'INFP', 'INFJ', 'INTP', 'INFJ', 'INFP', 'INTJ', 'INTJ', 'INFP', 'INFJ', 'INFP', 'INTP', 'INTP', 'INFJ', 'INFP', 'INFP', 'INFP', 'INFP', 'INTP', 'INFP', 'INFJ', 'INTP', 'INTP', 'INFP', 'INFP', 'INTJ', 'INTP', 'INTP', 'INTP', 'INTP', 'INFP', 'INFP', 'INTJ', 'INFJ', 'INTP', 'INTP', 'INTJ', 'INTP', 'INTP', 'INTP', 'INTP', 'INFP', 'INFJ', 'INFJ', 'INFJ', 'INFP', 'INTJ', 'INFP', 'INFJ', 'INFJ', 'INFP', 'INFJ', 'INTP', 'INFP', 'INFP', 'INFJ', 'INFJ', 'INFJ', 'INFP', 'INFP', 'INTJ', 'INFJ', 'INFP', 'INFP', 'INTP', 'INTJ', 'INTJ', 'INFJ', 'INTP', 'INTP', 'INTP', 'INFP', 'INFJ', 'INFP', 'INTJ', 'INTP', 'INFP', 'INFP', 'INTJ', 'INFJ', 'INFP', 'INFP', 'INFJ', 'INTP', 'INFP', 'INFP', 'INTJ', 'INFJ', 'INFP', 'INTP', 'INFP', 'INFP', 'INTJ', 'INTP', 'INTJ', 'INFP', 'INFP', 'INTP', 'INFP', 'INTP', 'INTJ', 'INFP', 'INFP', 'INTJ', 'INTP', 'INFP', 'INTP', 'INTJ', 'INTP', 'INTP', 'INTJ', 'INTP', 'INFJ', 'INTJ', 'INFP', 'INTP', 'INFP', 'INFP', 'INTJ', 'INFJ', 'INTP', 'INTJ', 'INFJ', 'INFP', 'INTJ', 'INFP', 'INFP', 'INFP', 'INFJ', 'INTP', 'INTP', 'INTP', 'INTP', 'INFP', 'INTP', 'INFP', 'INFP', 'INFP', 'INFP', 'INFP', 'INTP', 'INTJ', 'INFJ', 'INTJ', 'INTP', 'INFJ', 'INFP', 'INTP', 'INTP', 'INFP', 'INFP', 'INFJ', 'INFJ', 'INFP', 'INFP', 'INFJ', 'INFJ', 'INFJ', 'INFJ', 'INTP', 'INTP', 'INTP', 'INTP', 'INFJ', 'INFJ', 'INTP', 'INTP', 'INFP', 'INTJ', 'INFP', 'INFJ', 'INFJ', 'INFP', 'INTJ', 'INFJ', 'INFJ', 'INFJ', 'INTJ', 'INFP', 'INFP', 'INFP', 'INFP', 'INFP', 'INTJ', 'INFP', 'INFP', 'INFP', 'INTP', 'INFP', 'INFP', 'INTP', 'INFP', 'INFP', 'INFP', 'INTJ', 'INTP', 'INFJ', 'INTJ', 'INFP', 'INFP', 'INTJ', 'INFJ', 'INFP', 'INFP', 'INTP', 'INFJ', 'INTP', 'INFP', 'INTP', 'INTJ', 'INTJ', 'INFP', 'INFP', 'INTP', 'INTP', 'INTP', 'INFP', 'INFJ', 'INFP', 'INFP', 'INFJ', 'INTP', 'INFP', 'INTP', 'INTP', 'INFJ', 'INTP', 'INFP', 'INFP', 'INFJ', 'INTP', 'INTJ', 'INTJ', 'INTJ', 'INTP', 'INTP', 'INFJ', 'INFJ', 'INTP', 'INFP', 'INFP', 'INFP', 'INTP', 'INFJ', 'INFJ', 'INFJ', 'INTP', 'INFP', 'INFJ', 'INTP', 'INTP', 'INTJ', 'INFP', 'INFP', 'INFJ', 'INFP', 'INFJ', 'INTJ', 'INTP', 'INFJ', 'INTP', 'INTP', 'INTP', 'INFJ', 'INFP', 'INFP', 'INFP', 'INTJ', 'INFP', 'INFP', 'INTP', 'INTP', 'INTP', 'INFJ', 'INFP', 'INFP', 'INFP', 'INFP', 'INTP', 'INFP', 'INFJ', 'INTJ', 'INTJ', 'INFJ', 'INFP', 'INFJ', 'INFP', 'INTP', 'INTP', 'INFP', 'INTJ', 'INTJ', 'INFJ', 'INTP', 'INTP', 'INFJ', 'INFP', 'INFJ', 'INFP', 'INFP', 'INFJ', 'INFJ', 'INFJ', 'INFP', 'INFJ', 'INTP', 'INFP', 'INTP', 'INTP', 'INFJ', 'INTP', 'INTP', 'INTP', 'INTJ', 'INTP', 'INTP', 'INFP', 'INTJ', 'INFP', 'INFP', 'INFP', 'INTP', 'INFJ', 'INFP', 'INFJ', 'INTJ', 'INFP', 'INFP', 'INFP', 'INTP', 'INFP', 'INFJ', 'INFJ', 'INFP', 'INTP', 'INTP', 'INFP', 'INTP', 'INTP', 'INTJ', 'INTP', 'INTP', 'INFP', 'INFJ', 'INFJ', 'INFP', 'INTP', 'INFP', 'INTP', 'INTJ', 'INFP', 'INTP', 'INTP', 'INFP', 'INTJ', 'INFP', 'INTJ', 'INTP', 'INFJ', 'INFJ', 'INFJ', 'INTP', 'INTP', 'INTJ', 'INFP', 'INTP', 'INTJ', 'INFJ', 'INTP', 'INFJ', 'INTP', 'INTP', 'INFJ', 'INFP', 'INFP', 'INTJ', 'INTJ', 'INFP', 'INFP', 'INTP', 'INFP', 'INFP', 'INTP', 'INFP', 'INFJ', 'INTJ', 'INTP', 'INFP', 'INFJ', 'INFJ', 'INFP', 'INTP', 'INFP', 'INFP', 'INTP', 'INFP', 'INFJ', 'INFP', 'INTP', 'INFJ', 'INFJ', 'INTP', 'INTJ', 'INFP', 'INTP', 'INFP', 'INFP', 'INTP', 'INFJ', 'INFP', 'INFJ', 'INTP', 'INTJ', 'INTP', 'INFJ', 'INFP', 'INFP', 'INTP', 'INFP', 'INFP', 'INTP', 'INFJ', 'INFP', 'INFP', 'INFJ', 'INFP', 'INTP', 'INTJ', 'INTP', 'INTP', 'INTP', 'INTP', 'INTJ', 'INTJ', 'INTJ', 'INFP', 'INFP', 'INTP', 'INFP', 'INFJ', 'INTP', 'INTP', 'INTJ', 'INTP', 'INTP', 'INFJ', 'INFP', 'INFP', 'INFP', 'INFP', 'INFJ', 'INFP', 'INFP', 'INFJ', 'INTJ', 'INFJ', 'INTJ', 'INFP', 'INFJ', 'INFJ', 'INFP', 'INFP', 'INTJ', 'INFP', 'INTP', 'INFP', 'INFP', 'INFJ', 'INTP', 'INTJ', 'INTP', 'INFP', 'INFP', 'INFJ', 'INTP', 'INFP', 'INTP', 'INTP', 'INFJ', 'INTP', 'INTP', 'INTP', 'INFJ', 'INFP', 'INTP', 'INFJ', 'INFP', 'INTP', 'INTP', 'INFP', 'INFP', 'INTJ', 'INTJ', 'INTJ', 'INFJ', 'INTJ', 'INFJ', 'INFP', 'INTJ', 'INTP', 'INTJ', 'INTP', 'INFP', 'INTJ', 'INFP', 'INTP', 'INTP', 'INTP', 'INFP', 'INFP', 'INFP', 'INFP', 'INTP', 'INTP', 'INFP', 'INFP', 'INFJ', 'INTP', 'INFJ', 'INTP', 'INTJ', 'INFP', 'INTP', 'INTP', 'INFP', 'INTJ', 'INFP', 'INTP', 'INFJ', 'INFJ', 'INTP', 'INFJ', 'INFP', 'INFJ', 'INFJ', 'INFP', 'INFJ', 'INTP', 'INFP', 'INFJ', 'INTJ', 'INTJ', 'INTP', 'INTP', 'INTP', 'INTJ', 'INFP', 'INFP', 'INTP', 'INTP', 'INFJ', 'INFJ', 'INTJ', 'INFP', 'INFP', 'INFP', 'INFP', 'INFP', 'INTJ', 'INFP', 'INFJ', 'INFP', 'INFP', 'INFP', 'INTJ', 'INFJ', 'INFP', 'INTJ', 'INFP', 'INFP', 'INFP', 'INTP', 'INFP', 'INFP', 'INTP', 'INFP', 'INFP', 'INTP', 'INTP', 'INTP', 'INFP', 'INFP', 'INFP', 'INFJ', 'INFJ', 'INFJ', 'INFP', 'INTP', 'INTP', 'INTP', 'INTJ', 'INTP', 'INFP', 'INFJ', 'INFP', 'INTP', 'INFJ', 'INFJ', 'INFP', 'INTP', 'INFJ', 'INTJ', 'INTP', 'INFP', 'INTP', 'INTJ', 'INTP', 'INFP', 'INFJ', 'INTP', 'INFP', 'INTP', 'INFJ', 'INFJ', 'INTJ', 'INFP', 'INTP', 'INTP', 'INTP', 'INTP', 'INFP', 'INTJ', 'INFJ', 'INTP', 'INTP', 'INTP', 'INFP', 'INFP', 'INFP', 'INFJ', 'INFP', 'INFJ', 'INTJ', 'INFP', 'INTP', 'INTP', 'INTP', 'INFP', 'INTJ', 'INFP', 'INTJ', 'INTP', 'INTJ', 'INTP', 'INFJ', 'INTP', 'INFP', 'INFP', 'INFJ', 'INFP', 'INTP', 'INFP', 'INTP', 'INFP', 'INTP', 'INFP', 'INFP', 'INFP', 'INFP', 'INTP', 'INFP', 'INTP', 'INFP', 'INTJ', 'INFP', 'INFP', 'INFJ', 'INFJ', 'INFP', 'INFP', 'INFP', 'INFP', 'INTP', 'INFJ', 'INTP', 'INFP', 'INTP', 'INFP', 'INFP', 'INFP', 'INFJ', 'INFP', 'INTP', 'INFJ', 'INFP', 'INTP', 'INTP', 'INFP', 'INTP', 'INFP', 'INTJ', 'INTJ', 'INFJ', 'INTJ', 'INFJ', 'INTP', 'INFP', 'INFP', 'INTP', 'INFP', 'INFP', 'INFP', 'INFJ', 'INTP', 'INFP', 'INFP', 'INFJ', 'INFP', 'INTP', 'INTP', 'INFP', 'INFP', 'INTP', 'INFP', 'INFJ', 'INFP', 'INTJ', 'INTP', 'INFP', 'INFP', 'INFJ', 'INFP', 'INTP', 'INFP', 'INTP', 'INTJ', 'INTP', 'INFP', 'INFP', 'INFJ', 'INFP', 'INFP', 'INFJ', 'INTJ', 'INFP', 'INFJ', 'INFP', 'INTP', 'INFP', 'INFJ', 'INTP', 'INTJ', 'INTJ', 'INFP', 'INFP', 'INFP', 'INFJ', 'INFP', 'INFP', 'INFJ', 'INFJ', 'INFP', 'INFJ', 'INTP', 'INTP', 'INTP', 'INFP', 'INFP', 'INTJ', 'INFP', 'INFJ', 'INTJ', 'INTJ', 'INFP', 'INTJ', 'INFP', 'INFJ', 'INTP', 'INFP', 'INTJ', 'INTP', 'INTJ', 'INTJ', 'INFJ', 'INFP', 'INFP', 'INFJ', 'INTP', 'INFP', 'INTP', 'INFJ', 'INFP', 'INFP', 'INFJ', 'INTP', 'INFP', 'INFJ', 'INFJ', 'INTP', 'INTJ', 'INFP', 'INFJ', 'INTJ', 'INTP', 'INFP', 'INTP', 'INFP', 'INTP', 'INTJ', 'INFJ', 'INFJ', 'INFJ', 'INFP', 'INTP', 'INFJ', 'INFP', 'INTP', 'INFP', 'INTP', 'INFP', 'INFJ', 'INFJ', 'INFJ', 'INTJ', 'INFJ', 'INTP', 'INTJ', 'INFJ', 'INFP', 'INTJ', 'INTP', 'INFJ', 'INTP', 'INTJ', 'INTP', 'INFJ', 'INFP', 'INFP', 'INTP', 'INFP', 'INFP', 'INFP', 'INTJ', 'INTP', 'INFP', 'INFJ', 'INTJ', 'INTP', 'INTP', 'INFP', 'INTJ', 'INFP', 'INFJ', 'INFJ', 'INTP', 'INTJ', 'INFJ', 'INTJ', 'INTJ', 'INFP', 'INFP', 'INFP', 'INFP', 'INFJ', 'INFP', 'INTJ', 'INFP', 'INTP', 'INTJ', 'INTP', 'INFP', 'INTP', 'INFJ', 'INFP', 'INTJ', 'INTP', 'INTJ', 'INTP', 'INTJ', 'INTP', 'INTJ', 'INTP', 'INFJ', 'INTP', 'INFP', 'INFJ', 'INFJ', 'INTP', 'INFP', 'INFP', 'INTP', 'INTP', 'INFP', 'INTP', 'INTP', 'INFP', 'INFJ', 'INTP', 'INFP', 'INFP', 'INFJ', 'INFJ', 'INFJ', 'INTP', 'INTP', 'INFP', 'INFP', 'INTP', 'INTP', 'INFP', 'INFP', 'INFP', 'INTJ', 'INFP', 'INTP', 'INTJ', 'INTJ', 'INTP', 'INFP', 'INTJ', 'INFP', 'INFP', 'INTP', 'INFJ', 'INTJ', 'INTJ', 'INFJ', 'INTP', 'INFJ', 'INFJ', 'INFP', 'INFJ', 'INTP', 'INTJ', 'INFP', 'INTP', 'INTJ', 'INTP', 'INFP', 'INFJ', 'INFP', 'INFP', 'INFP', 'INTJ', 'INTP', 'INFJ', 'INFJ', 'INFP', 'INFJ', 'INFJ', 'INFP', 'INFP', 'INTP', 'INTJ', 'INFP', 'INTP', 'INFP', 'INFJ', 'INTJ', 'INTP', 'INFJ', 'INFP', 'INTP', 'INTP', 'INFP', 'INTJ', 'INTJ', 'INFP', 'INTP', 'INTJ', 'INFP', 'INFJ', 'INTJ', 'INTJ', 'INFP', 'INTP', 'INFJ', 'INFP', 'INTP', 'INTP', 'INTP', 'INFJ', 'INFP', 'INFJ', 'INTP', 'INFP', 'INTJ', 'INFJ', 'INTP', 'INFP', 'INFP', 'INTJ', 'INFJ', 'INFP', 'INFJ', 'INFJ', 'INTP', 'INTJ', 'INFP', 'INFP', 'INFP', 'INFJ', 'INTJ', 'INTP', 'INFJ', 'INFJ', 'INFJ', 'INTP', 'INFP', 'INFP', 'INTP', 'INFP', 'INTP', 'INTP', 'INFP', 'INTP', 'INFP', 'INTP', 'INFJ', 'INFP', 'INTJ', 'INTP', 'INFP', 'INFJ', 'INTJ', 'INFJ', 'INFP', 'INFP', 'INTP', 'INFP', 'INTJ', 'INTP', 'INFP', 'INFP', 'INFJ', 'INTJ', 'INTP', 'INFJ', 'INFP', 'INTJ', 'INFP', 'INFP', 'INFP', 'INFJ', 'INFP', 'INTP', 'INFP', 'INFP', 'INFJ', 'INFJ', 'INFJ', 'INFP', 'INFP', 'INFP', 'INFJ', 'INFJ', 'INTP', 'INTP', 'INTJ', 'INTP', 'INFP', 'INFJ', 'INTJ', 'INFJ', 'INFP', 'INFJ', 'INFP', 'INFP', 'INFJ', 'INFP', 'INTP', 'INTP', 'INTP', 'INFJ', 'INFP', 'INFP', 'INFJ', 'INFP', 'INTP', 'INFP', 'INFJ', 'INTP', 'INTP', 'INFJ', 'INTJ', 'INFP', 'INFP', 'INFP', 'INTJ', 'INTP', 'INFP', 'INTP', 'INFJ', 'INFJ', 'INTP', 'INFJ', 'INFP', 'INTP', 'INTP', 'INFP', 'INFJ', 'INFP', 'INFP', 'INTP', 'INFP', 'INTP', 'INTJ', 'INTP', 'INFJ', 'INTP', 'INFP', 'INFJ', 'INTJ', 'INFP', 'INFP', 'INFJ', 'INFP', 'INFJ', 'INFJ', 'INFJ', 'INTJ', 'INTP', 'INFJ', 'INTP', 'INTP', 'INFJ', 'INTP', 'INTP', 'INTP', 'INFP', 'INTJ', 'INTP', 'INTP', 'INTJ', 'INTP', 'INFP', 'INFP', 'INFJ', 'INFP', 'INFP', 'INFP', 'INFP', 'INFP', 'INFJ', 'INFP', 'INTJ', 'INTP', 'INTJ', 'INFP', 'INTP', 'INTJ', 'INFP', 'INFP', 'INFP', 'INFJ', 'INTJ', 'INFP', 'INFJ', 'INFJ', 'INTP', 'INFP', 'INTJ', 'INTJ', 'INFJ', 'INFJ', 'INTP', 'INTJ', 'INTP', 'INTP', 'INTP', 'INFP', 'INTP', 'INFP', 'INFP', 'INTP', 'INTJ', 'INTP', 'INFJ', 'INFJ', 'INFJ', 'INFP', 'INTJ', 'INFP', 'INTJ', 'INFP', 'INTP', 'INFJ', 'INFJ', 'INTP', 'INFP', 'INFP', 'INTJ', 'INFP', 'INFJ', 'INFJ', 'INFP', 'INFP', 'INFP', 'INTP', 'INTJ', 'INFP', 'INFP', 'INFP', 'INFP', 'INTP', 'INTP', 'INTP', 'INFJ', 'INTJ', 'INTP', 'INTJ', 'INFP', 'INTJ', 'INFJ', 'INTP', 'INFP', 'INTP', 'INTJ', 'INFP', 'INFP', 'INFJ', 'INTP', 'INTP', 'INFJ', 'INTP', 'INTJ', 'INFP', 'INFP', 'INTP', 'INFP', 'INFP', 'INTP', 'INTJ', 'INTP', 'INTJ', 'INFP', 'INTJ', 'INFP', 'INFJ', 'INTJ', 'INTJ', 'INFP', 'INTP', 'INTP', 'INFP', 'INFP', 'INTJ', 'INFP', 'INFJ', 'INTP', 'INTP']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = 0\n",
        "yy = y_test.type.values\n",
        "for i in range(len(predicted)):\n",
        "  if(predicted[i] == yy[i]):\n",
        "    t = t+1\n",
        "print(t/len(predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igPEbmbkr2Ui",
        "outputId": "c7fe74ce-35be-4e9a-a84f-46119827a3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4270893371757925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKB841_66SZW",
        "outputId": "afd35b31-36e9-4d60-f0d7-5124914370cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 87613 unique tokens.\n",
            "(12381, 500)\n",
            "Total 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "X_train_ei = X_over_ei.cleaned_post.values\n",
        "y_train_ei = y_over_ei.type_E.values\n",
        "X_test_ei = X_test.cleaned_post.values\n",
        "y_test_ei = y_test.type_E.values\n",
        "X_train_Glove,X_test_Glove, word_index,embeddings_index = loadData_Tokenizer((X_train_ei.tolist()),(X_test_ei.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex9eQo_p6cjc",
        "outputId": "3d6030d8-5a6a-48c7-d5ce-886c9438c0b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 500, 50)           4380700   \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 500, 50)           0         \n",
            "                                                                 \n",
            " conv1d_24 (Conv1D)          (None, 499, 256)          25856     \n",
            "                                                                 \n",
            " max_pooling1d_24 (MaxPoolin  (None, 249, 256)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_25 (Conv1D)          (None, 248, 256)          131328    \n",
            "                                                                 \n",
            " max_pooling1d_25 (MaxPoolin  (None, 124, 256)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_26 (Conv1D)          (None, 123, 256)          131328    \n",
            "                                                                 \n",
            " max_pooling1d_26 (MaxPoolin  (None, 61, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_27 (Conv1D)          (None, 60, 256)           131328    \n",
            "                                                                 \n",
            " max_pooling1d_27 (MaxPoolin  (None, 30, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " lstm_24 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_25 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_26 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_27 (LSTM)              (None, 256)               525312    \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1024)              263168    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 2)                 2050      \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,167,006\n",
            "Trainable params: 7,167,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "84/84 - 68s - loss: 0.6961 - accuracy: 0.5116 - val_loss: 0.6994 - val_accuracy: 0.2202 - 68s/epoch - 807ms/step\n",
            "Epoch 2/15\n",
            "84/84 - 52s - loss: 0.6933 - accuracy: 0.5033 - val_loss: 0.6880 - val_accuracy: 0.7798 - 52s/epoch - 623ms/step\n",
            "Epoch 3/15\n",
            "84/84 - 52s - loss: 0.6820 - accuracy: 0.5614 - val_loss: 0.8995 - val_accuracy: 0.3890 - 52s/epoch - 615ms/step\n",
            "Epoch 4/15\n",
            "84/84 - 51s - loss: 0.5058 - accuracy: 0.7597 - val_loss: 0.5375 - val_accuracy: 0.7579 - 51s/epoch - 609ms/step\n",
            "Epoch 5/15\n",
            "84/84 - 48s - loss: 0.3462 - accuracy: 0.8570 - val_loss: 0.5613 - val_accuracy: 0.7625 - 48s/epoch - 567ms/step\n",
            "Epoch 6/15\n",
            "84/84 - 49s - loss: 0.2611 - accuracy: 0.9023 - val_loss: 0.5430 - val_accuracy: 0.7654 - 49s/epoch - 585ms/step\n",
            "Epoch 7/15\n",
            "84/84 - 46s - loss: 0.1713 - accuracy: 0.9393 - val_loss: 0.4385 - val_accuracy: 0.8473 - 46s/epoch - 548ms/step\n",
            "Epoch 8/15\n",
            "84/84 - 48s - loss: 0.1214 - accuracy: 0.9600 - val_loss: 0.5939 - val_accuracy: 0.7925 - 48s/epoch - 574ms/step\n",
            "Epoch 9/15\n",
            "84/84 - 45s - loss: 0.0884 - accuracy: 0.9724 - val_loss: 0.9604 - val_accuracy: 0.6888 - 45s/epoch - 541ms/step\n",
            "Epoch 10/15\n",
            "84/84 - 46s - loss: 0.1055 - accuracy: 0.9652 - val_loss: 0.6644 - val_accuracy: 0.7937 - 46s/epoch - 549ms/step\n",
            "Epoch 11/15\n",
            "84/84 - 45s - loss: 0.0534 - accuracy: 0.9824 - val_loss: 0.7009 - val_accuracy: 0.7827 - 45s/epoch - 535ms/step\n",
            "Epoch 12/15\n",
            "84/84 - 44s - loss: 0.0460 - accuracy: 0.9855 - val_loss: 0.5550 - val_accuracy: 0.8144 - 44s/epoch - 520ms/step\n",
            "Epoch 13/15\n",
            "84/84 - 43s - loss: 0.0386 - accuracy: 0.9875 - val_loss: 0.6051 - val_accuracy: 0.8179 - 43s/epoch - 509ms/step\n",
            "Epoch 14/15\n",
            "84/84 - 44s - loss: 0.0268 - accuracy: 0.9919 - val_loss: 0.7538 - val_accuracy: 0.8421 - 44s/epoch - 521ms/step\n",
            "Epoch 15/15\n",
            "84/84 - 45s - loss: 0.0323 - accuracy: 0.9903 - val_loss: 0.7860 - val_accuracy: 0.8161 - 45s/epoch - 537ms/step\n",
            "55/55 [==============================] - 3s 36ms/step\n",
            "With oversample ei\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.83      0.88      1353\n",
            "           1       0.56      0.77      0.65       382\n",
            "\n",
            "    accuracy                           0.82      1735\n",
            "   macro avg       0.74      0.80      0.76      1735\n",
            "weighted avg       0.85      0.82      0.83      1735\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_RCNN_ei = Build_Model_RCNN_Text(word_index,embeddings_index, 2)\n",
        "\n",
        "\n",
        "model_RCNN_ei.summary()\n",
        "\n",
        "model_RCNN_ei.fit(X_train_Glove, y_train_ei,\n",
        "                              validation_data=(X_test_Glove, y_test_ei),\n",
        "                              epochs=15,\n",
        "                              batch_size=128,\n",
        "                              verbose=2)\n",
        "model_RCNN_ei.save('/content/drive/MyDrive/model_RCNN_ei.h5')\n",
        "\n",
        "predicted_ei = model_RCNN_ei.predict(X_test_Glove)\n",
        "\n",
        "predicted_ei = np.argmax(predicted_ei, axis=1)\n",
        "print(\"With oversample ei\")\n",
        "print(metrics.classification_report(y_test_ei, predicted_ei))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iy2QLSzZ6yZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea665d5e-e307-4ae4-e907-ec5b8dd28c16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6475138121546962\n",
            "0.8161383285302594\n",
            "0.5602294455066922\n",
            "0.7670157068062827\n"
          ]
        }
      ],
      "source": [
        "print(metrics.f1_score(y_test_ei, predicted_ei))\n",
        "print(metrics.accuracy_score(y_test_ei, predicted_ei))\n",
        "print(metrics.precision_score(y_test_ei, predicted_ei))\n",
        "print(metrics.recall_score(y_test_ei, predicted_ei))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrGnBZv16zcG",
        "outputId": "9d7aee4c-69b6-4a66-f43a-8f1a724de647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 87613 unique tokens.\n",
            "(10085, 500)\n",
            "Total 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "X_train_jp = X_over_jp.cleaned_post.values\n",
        "y_train_jp = y_over_jp.type_J.values\n",
        "X_test_jp = X_test.cleaned_post.values\n",
        "y_test_jp = y_test.type_J.values\n",
        "X_train_Glove,X_test_Glove, word_index,embeddings_index = loadData_Tokenizer((X_train_jp.tolist()),(X_test_jp.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp2HBaFG7KpL",
        "outputId": "c918da58-fe96-448e-cabf-e957436ed0d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 500, 50)           4380700   \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 500, 50)           0         \n",
            "                                                                 \n",
            " conv1d_28 (Conv1D)          (None, 499, 256)          25856     \n",
            "                                                                 \n",
            " max_pooling1d_28 (MaxPoolin  (None, 249, 256)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_29 (Conv1D)          (None, 248, 256)          131328    \n",
            "                                                                 \n",
            " max_pooling1d_29 (MaxPoolin  (None, 124, 256)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_30 (Conv1D)          (None, 123, 256)          131328    \n",
            "                                                                 \n",
            " max_pooling1d_30 (MaxPoolin  (None, 61, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_31 (Conv1D)          (None, 60, 256)           131328    \n",
            "                                                                 \n",
            " max_pooling1d_31 (MaxPoolin  (None, 30, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " lstm_28 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_29 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_30 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_31 (LSTM)              (None, 256)               525312    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1024)              263168    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 2)                 2050      \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,167,006\n",
            "Trainable params: 7,167,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "66/66 - 54s - loss: 0.6949 - accuracy: 0.5011 - val_loss: 0.6900 - val_accuracy: 0.6144 - 54s/epoch - 821ms/step\n",
            "Epoch 2/25\n",
            "66/66 - 40s - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.7209 - val_accuracy: 0.3856 - 40s/epoch - 613ms/step\n",
            "Epoch 3/25\n",
            "66/66 - 40s - loss: 0.6938 - accuracy: 0.4999 - val_loss: 0.6935 - val_accuracy: 0.3856 - 40s/epoch - 605ms/step\n",
            "Epoch 4/25\n",
            "66/66 - 40s - loss: 0.6936 - accuracy: 0.5006 - val_loss: 0.6928 - val_accuracy: 0.6144 - 40s/epoch - 609ms/step\n",
            "Epoch 5/25\n",
            "66/66 - 39s - loss: 0.6949 - accuracy: 0.5081 - val_loss: 0.6926 - val_accuracy: 0.6144 - 39s/epoch - 590ms/step\n",
            "Epoch 6/25\n",
            "66/66 - 39s - loss: 0.6935 - accuracy: 0.4968 - val_loss: 0.6952 - val_accuracy: 0.3856 - 39s/epoch - 586ms/step\n",
            "Epoch 7/25\n",
            "66/66 - 38s - loss: 0.6871 - accuracy: 0.5273 - val_loss: 0.6712 - val_accuracy: 0.6421 - 38s/epoch - 582ms/step\n",
            "Epoch 8/25\n",
            "66/66 - 37s - loss: 0.6924 - accuracy: 0.5047 - val_loss: 0.6913 - val_accuracy: 0.3919 - 37s/epoch - 565ms/step\n",
            "Epoch 9/25\n",
            "66/66 - 36s - loss: 0.6728 - accuracy: 0.5851 - val_loss: 0.6442 - val_accuracy: 0.6519 - 36s/epoch - 545ms/step\n",
            "Epoch 10/25\n",
            "66/66 - 37s - loss: 0.5725 - accuracy: 0.7165 - val_loss: 0.5393 - val_accuracy: 0.7516 - 37s/epoch - 566ms/step\n",
            "Epoch 11/25\n",
            "66/66 - 36s - loss: 0.4087 - accuracy: 0.8272 - val_loss: 0.5115 - val_accuracy: 0.7787 - 36s/epoch - 547ms/step\n",
            "Epoch 12/25\n",
            "66/66 - 35s - loss: 0.3196 - accuracy: 0.8743 - val_loss: 0.6918 - val_accuracy: 0.7862 - 35s/epoch - 531ms/step\n",
            "Epoch 13/25\n",
            "66/66 - 35s - loss: 0.2424 - accuracy: 0.9062 - val_loss: 0.4948 - val_accuracy: 0.8052 - 35s/epoch - 535ms/step\n",
            "Epoch 14/25\n",
            "66/66 - 35s - loss: 0.1606 - accuracy: 0.9428 - val_loss: 0.6350 - val_accuracy: 0.7896 - 35s/epoch - 527ms/step\n",
            "Epoch 15/25\n",
            "66/66 - 35s - loss: 0.1267 - accuracy: 0.9529 - val_loss: 0.7565 - val_accuracy: 0.7718 - 35s/epoch - 531ms/step\n",
            "Epoch 16/25\n",
            "66/66 - 37s - loss: 0.0944 - accuracy: 0.9686 - val_loss: 0.7635 - val_accuracy: 0.7793 - 37s/epoch - 556ms/step\n",
            "Epoch 17/25\n",
            "66/66 - 33s - loss: 0.0893 - accuracy: 0.9705 - val_loss: 0.7477 - val_accuracy: 0.7896 - 33s/epoch - 507ms/step\n",
            "Epoch 18/25\n",
            "66/66 - 34s - loss: 0.0649 - accuracy: 0.9800 - val_loss: 1.0352 - val_accuracy: 0.7493 - 34s/epoch - 522ms/step\n",
            "Epoch 19/25\n",
            "66/66 - 34s - loss: 0.0599 - accuracy: 0.9806 - val_loss: 0.9781 - val_accuracy: 0.7718 - 34s/epoch - 510ms/step\n",
            "Epoch 20/25\n",
            "66/66 - 35s - loss: 0.0501 - accuracy: 0.9837 - val_loss: 0.7439 - val_accuracy: 0.7844 - 35s/epoch - 535ms/step\n",
            "Epoch 21/25\n",
            "66/66 - 33s - loss: 0.0425 - accuracy: 0.9869 - val_loss: 0.8453 - val_accuracy: 0.7937 - 33s/epoch - 506ms/step\n",
            "Epoch 22/25\n",
            "66/66 - 35s - loss: 0.0399 - accuracy: 0.9881 - val_loss: 1.0204 - val_accuracy: 0.7700 - 35s/epoch - 530ms/step\n",
            "Epoch 23/25\n",
            "66/66 - 33s - loss: 0.0316 - accuracy: 0.9910 - val_loss: 1.1441 - val_accuracy: 0.7706 - 33s/epoch - 498ms/step\n",
            "Epoch 24/25\n",
            "66/66 - 35s - loss: 0.0223 - accuracy: 0.9939 - val_loss: 0.8331 - val_accuracy: 0.7873 - 35s/epoch - 528ms/step\n",
            "Epoch 25/25\n",
            "66/66 - 33s - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.9479 - val_accuracy: 0.7723 - 33s/epoch - 494ms/step\n",
            "55/55 [==============================] - 3s 41ms/step\n",
            "With oversample jp\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.93      0.83      1066\n",
            "           1       0.82      0.53      0.64       669\n",
            "\n",
            "    accuracy                           0.77      1735\n",
            "   macro avg       0.79      0.73      0.74      1735\n",
            "weighted avg       0.78      0.77      0.76      1735\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_RCNN_jp = Build_Model_RCNN_Text(word_index,embeddings_index, 2)\n",
        "\n",
        "\n",
        "model_RCNN_jp.summary()\n",
        "\n",
        "model_RCNN_jp.fit(X_train_Glove, y_train_jp,\n",
        "                              validation_data=(X_test_Glove, y_test_jp),\n",
        "                              epochs=25,\n",
        "                              batch_size=128,\n",
        "                              verbose=2)\n",
        "\n",
        "model_RCNN_jp.save('/content/drive/MyDrive/model_RCNN_jp.h5')\n",
        "\n",
        "predicted_jp = model_RCNN_jp.predict(X_test_Glove)\n",
        "\n",
        "predicted_jp = np.argmax(predicted_jp, axis=1)\n",
        "print(\"With oversample jp\")\n",
        "print(metrics.classification_report(y_test_jp, predicted_jp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o34HJYY67fb8",
        "outputId": "f677ca13-3533-462e-d678-4eabdae9b73e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.640582347588717\n",
            "0.7723342939481268\n",
            "0.8186046511627907\n",
            "0.5261584454409567\n"
          ]
        }
      ],
      "source": [
        "print(metrics.f1_score(y_test_jp, predicted_jp))\n",
        "print(metrics.accuracy_score(y_test_jp, predicted_jp))\n",
        "print(metrics.precision_score(y_test_jp, predicted_jp))\n",
        "print(metrics.recall_score(y_test_jp, predicted_jp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN43nChT7qZc",
        "outputId": "5f7f4a75-dae1-4713-dd9c-5cbd409e2b78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 87613 unique tokens.\n",
            "(9249, 500)\n",
            "Total 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "X_train_ft = X_over_ft.cleaned_post.values\n",
        "y_train_ft = y_over_ft.type_F.values\n",
        "X_test_ft = X_test.cleaned_post.values\n",
        "y_test_ft = y_test.type_F.values\n",
        "X_train_Glove,X_test_Glove, word_index,embeddings_index = loadData_Tokenizer((X_train_ft.tolist()),(X_test_ft.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-mNqcJd76Wl",
        "outputId": "ffa171ea-ad05-4b67-87aa-dc676fb5f798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 500, 50)           4380700   \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 500, 50)           0         \n",
            "                                                                 \n",
            " conv1d_32 (Conv1D)          (None, 499, 256)          25856     \n",
            "                                                                 \n",
            " max_pooling1d_32 (MaxPoolin  (None, 249, 256)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_33 (Conv1D)          (None, 248, 256)          131328    \n",
            "                                                                 \n",
            " max_pooling1d_33 (MaxPoolin  (None, 124, 256)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_34 (Conv1D)          (None, 123, 256)          131328    \n",
            "                                                                 \n",
            " max_pooling1d_34 (MaxPoolin  (None, 61, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_35 (Conv1D)          (None, 60, 256)           131328    \n",
            "                                                                 \n",
            " max_pooling1d_35 (MaxPoolin  (None, 30, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " lstm_32 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_33 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_34 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_35 (LSTM)              (None, 256)               525312    \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1024)              263168    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 2)                 2050      \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,167,006\n",
            "Trainable params: 7,167,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "59/59 - 51s - loss: 0.6944 - accuracy: 0.5200 - val_loss: 0.6319 - val_accuracy: 0.6686 - 51s/epoch - 860ms/step\n",
            "Epoch 2/15\n",
            "59/59 - 38s - loss: 0.6649 - accuracy: 0.6066 - val_loss: 0.6269 - val_accuracy: 0.6916 - 38s/epoch - 643ms/step\n",
            "Epoch 3/15\n",
            "59/59 - 36s - loss: 0.5649 - accuracy: 0.7144 - val_loss: 0.5320 - val_accuracy: 0.7435 - 36s/epoch - 604ms/step\n",
            "Epoch 4/15\n",
            "59/59 - 36s - loss: 0.5135 - accuracy: 0.7585 - val_loss: 0.4841 - val_accuracy: 0.7712 - 36s/epoch - 616ms/step\n",
            "Epoch 5/15\n",
            "59/59 - 37s - loss: 0.3887 - accuracy: 0.8350 - val_loss: 0.5020 - val_accuracy: 0.8012 - 37s/epoch - 629ms/step\n",
            "Epoch 6/15\n",
            "59/59 - 35s - loss: 0.3334 - accuracy: 0.8655 - val_loss: 0.4177 - val_accuracy: 0.8352 - 35s/epoch - 593ms/step\n",
            "Epoch 7/15\n",
            "59/59 - 35s - loss: 0.2732 - accuracy: 0.8954 - val_loss: 0.5396 - val_accuracy: 0.8035 - 35s/epoch - 588ms/step\n",
            "Epoch 8/15\n",
            "59/59 - 35s - loss: 0.2349 - accuracy: 0.9130 - val_loss: 0.4691 - val_accuracy: 0.8346 - 35s/epoch - 596ms/step\n",
            "Epoch 9/15\n",
            "59/59 - 32s - loss: 0.1813 - accuracy: 0.9369 - val_loss: 0.4409 - val_accuracy: 0.8363 - 32s/epoch - 550ms/step\n",
            "Epoch 10/15\n",
            "59/59 - 31s - loss: 0.1710 - accuracy: 0.9392 - val_loss: 0.5097 - val_accuracy: 0.8196 - 31s/epoch - 528ms/step\n",
            "Epoch 11/15\n",
            "59/59 - 34s - loss: 0.1198 - accuracy: 0.9611 - val_loss: 0.5280 - val_accuracy: 0.8242 - 34s/epoch - 571ms/step\n",
            "Epoch 12/15\n",
            "59/59 - 32s - loss: 0.0978 - accuracy: 0.9706 - val_loss: 0.6451 - val_accuracy: 0.8150 - 32s/epoch - 535ms/step\n",
            "Epoch 13/15\n",
            "59/59 - 32s - loss: 0.0974 - accuracy: 0.9703 - val_loss: 0.5666 - val_accuracy: 0.8196 - 32s/epoch - 544ms/step\n",
            "Epoch 14/15\n",
            "59/59 - 33s - loss: 0.0788 - accuracy: 0.9766 - val_loss: 0.6450 - val_accuracy: 0.8219 - 33s/epoch - 552ms/step\n",
            "Epoch 15/15\n",
            "59/59 - 32s - loss: 0.0730 - accuracy: 0.9756 - val_loss: 0.7417 - val_accuracy: 0.8167 - 32s/epoch - 541ms/step\n",
            "55/55 [==============================] - 4s 55ms/step\n",
            "With oversample ft\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       798\n",
            "           1       0.80      0.89      0.84       937\n",
            "\n",
            "    accuracy                           0.82      1735\n",
            "   macro avg       0.82      0.81      0.81      1735\n",
            "weighted avg       0.82      0.82      0.82      1735\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_RCNN_ft = Build_Model_RCNN_Text(word_index,embeddings_index, 2)\n",
        "\n",
        "\n",
        "model_RCNN_ft.summary()\n",
        "\n",
        "model_RCNN_ft.fit(X_train_Glove, y_train_ft,\n",
        "                              validation_data=(X_test_Glove, y_test_ft),\n",
        "                              epochs=15,\n",
        "                              batch_size=128,\n",
        "                              verbose=2)\n",
        "model_RCNN_ft.save('/content/drive/MyDrive/model_RCNN_ft.h5')\n",
        "\n",
        "predicted_ft = model_RCNN_ft.predict(X_test_Glove)\n",
        "\n",
        "predicted_ft = np.argmax(predicted_ft, axis=1)\n",
        "print(\"With oversample ft\")\n",
        "print(metrics.classification_report(y_test_ft, predicted_ft))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aad8YtiY8Etd",
        "outputId": "f36c9f82-adf4-4743-9a04-3c4ff65cb506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.839231547017189\n",
            "0.8167146974063401\n",
            "0.7973102785782901\n",
            "0.8858057630736392\n"
          ]
        }
      ],
      "source": [
        "print(metrics.f1_score(y_test_ft, predicted_ft))\n",
        "print(metrics.accuracy_score(y_test_ft, predicted_ft))\n",
        "print(metrics.precision_score(y_test_ft, predicted_ft))\n",
        "print(metrics.recall_score(y_test_ft, predicted_ft))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrYR2VFW8APr",
        "outputId": "f7110bfa-76a4-41c1-e795-592c13c97882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 87613 unique tokens.\n",
            "(13713, 500)\n",
            "Total 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "X_train_ns = X_over_ns.cleaned_post.values\n",
        "y_train_ns = y_over_ns.type_N.values\n",
        "X_test_ns = X_test.cleaned_post.values\n",
        "y_test_ns = y_test.type_N.values\n",
        "X_train_Glove,X_test_Glove, word_index,embeddings_index = loadData_Tokenizer((X_train_ns.tolist()),(X_test_ns.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc8kJmfi8NGp",
        "outputId": "bbb2074d-0d37-4536-8a24-29c477a069ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 500, 50)           4380700   \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 500, 50)           0         \n",
            "                                                                 \n",
            " conv1d_36 (Conv1D)          (None, 499, 256)          25856     \n",
            "                                                                 \n",
            " max_pooling1d_36 (MaxPoolin  (None, 249, 256)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_37 (Conv1D)          (None, 248, 256)          131328    \n",
            "                                                                 \n",
            " max_pooling1d_37 (MaxPoolin  (None, 124, 256)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_38 (Conv1D)          (None, 123, 256)          131328    \n",
            "                                                                 \n",
            " max_pooling1d_38 (MaxPoolin  (None, 61, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_39 (Conv1D)          (None, 60, 256)           131328    \n",
            "                                                                 \n",
            " max_pooling1d_39 (MaxPoolin  (None, 30, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " lstm_36 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_37 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_38 (LSTM)              (None, 30, 256)           525312    \n",
            "                                                                 \n",
            " lstm_39 (LSTM)              (None, 256)               525312    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1024)              263168    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 2)                 2050      \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,167,006\n",
            "Trainable params: 7,167,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "94/94 - 72s - loss: 0.6974 - accuracy: 0.5123 - val_loss: 0.6707 - val_accuracy: 0.7303 - 72s/epoch - 766ms/step\n",
            "Epoch 2/15\n",
            "94/94 - 58s - loss: 0.6093 - accuracy: 0.6721 - val_loss: 0.4284 - val_accuracy: 0.8352 - 58s/epoch - 618ms/step\n",
            "Epoch 3/15\n",
            "94/94 - 56s - loss: 0.3961 - accuracy: 0.8334 - val_loss: 0.2871 - val_accuracy: 0.8986 - 56s/epoch - 599ms/step\n",
            "Epoch 4/15\n",
            "94/94 - 56s - loss: 0.2383 - accuracy: 0.9093 - val_loss: 0.3484 - val_accuracy: 0.8726 - 56s/epoch - 591ms/step\n",
            "Epoch 5/15\n",
            "94/94 - 55s - loss: 0.1467 - accuracy: 0.9487 - val_loss: 0.4022 - val_accuracy: 0.8450 - 55s/epoch - 584ms/step\n",
            "Epoch 6/15\n",
            "94/94 - 54s - loss: 0.1044 - accuracy: 0.9680 - val_loss: 0.4704 - val_accuracy: 0.8398 - 54s/epoch - 576ms/step\n",
            "Epoch 7/15\n",
            "94/94 - 51s - loss: 0.0782 - accuracy: 0.9750 - val_loss: 0.4563 - val_accuracy: 0.8559 - 51s/epoch - 546ms/step\n",
            "Epoch 8/15\n",
            "94/94 - 52s - loss: 0.0513 - accuracy: 0.9847 - val_loss: 0.5012 - val_accuracy: 0.8513 - 52s/epoch - 551ms/step\n",
            "Epoch 9/15\n",
            "94/94 - 49s - loss: 0.0447 - accuracy: 0.9858 - val_loss: 0.5734 - val_accuracy: 0.8248 - 49s/epoch - 523ms/step\n",
            "Epoch 10/15\n",
            "94/94 - 50s - loss: 0.0352 - accuracy: 0.9890 - val_loss: 0.5776 - val_accuracy: 0.9055 - 50s/epoch - 537ms/step\n",
            "Epoch 11/15\n",
            "94/94 - 47s - loss: 0.0365 - accuracy: 0.9891 - val_loss: 0.5730 - val_accuracy: 0.7960 - 47s/epoch - 505ms/step\n",
            "Epoch 12/15\n",
            "94/94 - 50s - loss: 0.0277 - accuracy: 0.9912 - val_loss: 0.7917 - val_accuracy: 0.8461 - 50s/epoch - 530ms/step\n",
            "Epoch 13/15\n",
            "94/94 - 51s - loss: 0.0174 - accuracy: 0.9948 - val_loss: 0.6148 - val_accuracy: 0.8847 - 51s/epoch - 541ms/step\n",
            "Epoch 14/15\n",
            "94/94 - 48s - loss: 0.0230 - accuracy: 0.9924 - val_loss: 0.5367 - val_accuracy: 0.8957 - 48s/epoch - 513ms/step\n",
            "Epoch 15/15\n",
            "94/94 - 51s - loss: 0.0285 - accuracy: 0.9924 - val_loss: 0.5312 - val_accuracy: 0.8957 - 51s/epoch - 546ms/step\n",
            "55/55 [==============================] - 3s 38ms/step\n",
            "With oversample ns\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.60      0.62       246\n",
            "           1       0.93      0.94      0.94      1489\n",
            "\n",
            "    accuracy                           0.90      1735\n",
            "   macro avg       0.79      0.77      0.78      1735\n",
            "weighted avg       0.89      0.90      0.89      1735\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_RCNN_ns = Build_Model_RCNN_Text(word_index,embeddings_index, 2)\n",
        "\n",
        "\n",
        "model_RCNN_ns.summary()\n",
        "\n",
        "model_RCNN_ns.fit(X_train_Glove, y_train_ns,\n",
        "                              validation_data=(X_test_Glove, y_test_ns),\n",
        "                              epochs=15,\n",
        "                              batch_size=128,\n",
        "                              verbose=2)\n",
        "\n",
        "model_RCNN_ns.save('/content/drive/MyDrive/model_RCNN_ns.h5')\n",
        "\n",
        "predicted_ns = model_RCNN_ns.predict(X_test_Glove)\n",
        "\n",
        "predicted_ns = np.argmax(predicted_ns, axis=1)\n",
        "print(\"With oversample ns\")\n",
        "print(metrics.classification_report(y_test_ns, predicted_ns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwISUSUi8Uqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e133b73f-2fce-4863-c4cd-182ab12f2f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9395255596391581\n",
            "0.8956772334293948\n",
            "0.9348404255319149\n",
            "0.9442578912021491\n"
          ]
        }
      ],
      "source": [
        "print(metrics.f1_score(y_test_ns, predicted_ns))\n",
        "print(metrics.accuracy_score(y_test_ns, predicted_ns))\n",
        "print(metrics.precision_score(y_test_ns, predicted_ns))\n",
        "print(metrics.recall_score(y_test_ns, predicted_ns))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E_I = predicted_ei\n",
        "J_P = predicted_jp\n",
        "F_T = predicted_ft\n",
        "N_S = predicted_ns"
      ],
      "metadata": {
        "id": "KLGfKHdUBJ6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = []\n",
        "for i in range(len(E_I)):\n",
        "  s = \"\"\n",
        "  #enfj\n",
        "  if(E_I[i] == 0) :\n",
        "    s = s + \"I\"\n",
        "  else :\n",
        "    s = s + \"E\"\n",
        "  if (N_S[i] == 0) :\n",
        "    s = s + \"S\"\n",
        "  else:\n",
        "    s = s + \"N\"\n",
        "  if (F_T[i] == 0) :\n",
        "    s = s + \"T\"\n",
        "  else:\n",
        "    s = s + \"F\"\n",
        "  if (J_P[i] == 0) :\n",
        "    s = s + \"P\"\n",
        "  else:\n",
        "    s = s + \"J\"\n",
        "  predicted.append(s)\n",
        "print(predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYCbd2xdG6Qu",
        "outputId": "a188102a-ce3f-48a3-e86b-d6a776900100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ENTP', 'INFJ', 'INTP', 'ENFP', 'INTJ', 'INFJ', 'ENFJ', 'INTP', 'ENTP', 'INTP', 'ENFP', 'INTP', 'ENFJ', 'ENFP', 'ISTP', 'INFP', 'ENTP', 'INTP', 'INFP', 'INFP', 'ENFP', 'INTP', 'ENTJ', 'ENFP', 'INTP', 'INTJ', 'INTP', 'INTJ', 'INTP', 'ENTP', 'INTP', 'ENTP', 'INTP', 'ISFP', 'ENFP', 'INTP', 'INFJ', 'ENFJ', 'INTP', 'INFP', 'INTJ', 'ENFP', 'INTP', 'INFP', 'ENFP', 'ENFP', 'INFP', 'ISFP', 'ENFP', 'INTJ', 'INFJ', 'ENTP', 'INTP', 'INFP', 'ISTJ', 'INFP', 'ENTP', 'INFJ', 'INFP', 'ENTP', 'ENTJ', 'INFP', 'ESTP', 'INTP', 'ENTP', 'ISTP', 'INTP', 'INFP', 'INFP', 'INTP', 'INFP', 'ENFP', 'INTP', 'ENTP', 'ENTP', 'INFP', 'INFP', 'ENTP', 'INFP', 'INTJ', 'INTP', 'ENFJ', 'INFJ', 'INTP', 'INFP', 'ENTJ', 'ISFP', 'INTJ', 'INTP', 'ENFP', 'INTP', 'ENFP', 'INTP', 'INFP', 'ENFP', 'INTJ', 'INTP', 'INFJ', 'ENFJ', 'INFP', 'INFP', 'ISFJ', 'ISFJ', 'INFJ', 'ENTP', 'ENTP', 'ESTP', 'INTP', 'INTP', 'INTP', 'INFP', 'INTJ', 'ENFP', 'ENFP', 'INFP', 'INFP', 'INFJ', 'INFP', 'INFJ', 'INFP', 'ENFJ', 'INFP', 'INTP', 'INTP', 'INTP', 'ENFP', 'INFP', 'INTJ', 'ISTJ', 'INTP', 'INTJ', 'ENFP', 'INFP', 'ISFJ', 'INFP', 'ISFP', 'INTP', 'ENTP', 'INTP', 'INFP', 'INFJ', 'INFP', 'INTP', 'INFJ', 'ENFJ', 'INTP', 'INFP', 'INFP', 'INFP', 'INFP', 'ENFP', 'INTP', 'INTP', 'ENFP', 'ESTP', 'INFP', 'INTP', 'ISTP', 'ENFP', 'INFP', 'INTP', 'INFP', 'ENFP', 'ENTP', 'ESFP', 'INFP', 'INFP', 'INFP', 'ENFP', 'INTJ', 'ENTJ', 'ENFP', 'ENFP', 'INTP', 'INFP', 'ISFJ', 'ISFP', 'INTJ', 'ENFP', 'ENFP', 'ENFP', 'INTP', 'ENTP', 'ISTJ', 'INTJ', 'INFJ', 'INFP', 'INFP', 'INFP', 'INTP', 'INFP', 'INTJ', 'INFJ', 'ESFP', 'INFJ', 'INFP', 'INFP', 'ENFP', 'ISTJ', 'INFP', 'INFP', 'ENFJ', 'INFP', 'ENFP', 'ISTP', 'INTP', 'ISTJ', 'ISFJ', 'INTP', 'ESTP', 'ISFP', 'INTP', 'INFP', 'INFP', 'ENFJ', 'INFP', 'INTJ', 'INTJ', 'ENTP', 'INTP', 'INFJ', 'ENTP', 'INFP', 'INTP', 'INTJ', 'INFP', 'ISFP', 'ENFJ', 'INTP', 'ISTP', 'INTP', 'INFJ', 'INTP', 'ISFP', 'INTJ', 'ENTP', 'ENTP', 'INFP', 'INTP', 'ENFJ', 'ENTP', 'ISFP', 'INFP', 'INTP', 'ENFP', 'ENFP', 'INTJ', 'ENFP', 'ENFP', 'INFP', 'INTP', 'INFP', 'INTP', 'ISFP', 'ISFP', 'ENFJ', 'INTJ', 'ENFP', 'INFP', 'INFP', 'ENFP', 'ENFP', 'INFP', 'INTP', 'INFJ', 'INTP', 'INFP', 'INTP', 'INTP', 'INFP', 'INFP', 'INTP', 'INFJ', 'INFP', 'ISFP', 'INTJ', 'ISFP', 'INFP', 'INTP', 'ENFP', 'ENTP', 'ENFP', 'INFP', 'INTP', 'INFP', 'ENFP', 'INFP', 'INFJ', 'INFP', 'INTJ', 'ENFP', 'INFP', 'INFP', 'INTJ', 'INFJ', 'ENFP', 'INTJ', 'INFP', 'ENTP', 'ESTP', 'INTP', 'INFP', 'INTP', 'ENFP', 'ISFJ', 'INFP', 'ESFP', 'ENFP', 'INFP', 'INTP', 'INFP', 'INFJ', 'INFP', 'INFP', 'ENFP', 'ENFP', 'ENFP', 'ESFJ', 'ENFP', 'INTP', 'INFP', 'ENFJ', 'ENFP', 'ENTP', 'INFP', 'INFJ', 'INFP', 'INFP', 'INTP', 'ESFP', 'INFP', 'INFP', 'INFP', 'ISTP', 'INTP', 'ENFP', 'INFP', 'ISFP', 'INTP', 'INFP', 'INFP', 'INFP', 'INFJ', 'INTP', 'INFP', 'INFP', 'INFJ', 'INTP', 'INFP', 'ENTP', 'INTJ', 'INTJ', 'INFP', 'INFP', 'INFP', 'ISTP', 'INTJ', 'INTP', 'INTP', 'INTP', 'INFP', 'INTJ', 'INFJ', 'INFP', 'INTJ', 'INTP', 'ISTJ', 'ESTP', 'INFJ', 'INFJ', 'ENFP', 'ESTJ', 'INFP', 'ENFP', 'INFJ', 'INTP', 'ENFJ', 'ENTJ', 'INTP', 'ENFP', 'INFP', 'INFP', 'INTP', 'INTJ', 'INTP', 'INFJ', 'ISFP', 'INFJ', 'INFP', 'ISFP', 'INFP', 'INFP', 'INFP', 'INFP', 'ISFP', 'INTP', 'INFP', 'INFP', 'ESFJ', 'INFP', 'INTJ', 'ESFP', 'INFJ', 'INTJ', 'ESTP', 'INFP', 'ENTP', 'INTP', 'INFP', 'INTP', 'ISTP', 'INFP', 'INTP', 'INFJ', 'INFP', 'INTP', 'ENFP', 'ISFP', 'INFP', 'INFJ', 'INFP', 'INFP', 'INFP', 'INTP', 'INFJ', 'INFJ', 'ENTP', 'ENTJ', 'ENTP', 'INFJ', 'INFP', 'INTP', 'INFP', 'ENTP', 'INFP', 'ISFP', 'INFP', 'INTJ', 'ISTJ', 'INTP', 'INFP', 'INTP', 'INFP', 'INTP', 'INFP', 'INTP', 'INFJ', 'INTJ', 'INFP', 'ISFP', 'INFP', 'ESFJ', 'INFP', 'INFJ', 'INTP', 'INFP', 'ENFP', 'ISFP', 'INFP', 'INFP', 'INFP', 'ENFP', 'ENTP', 'ENFP', 'ESTP', 'INFP', 'INFP', 'INTJ', 'ENFP', 'INFP', 'INTJ', 'INFP', 'ENFJ', 'INFP', 'INFP', 'ISTP', 'INFP', 'INFJ', 'ENTP', 'ENFP', 'INFJ', 'ESFJ', 'ENFP', 'ENFP', 'INTP', 'INFP', 'INFJ', 'INFJ', 'ISFP', 'ISTP', 'ENFP', 'ESFP', 'ENTJ', 'INFP', 'INFJ', 'INFP', 'INFP', 'ISTP', 'INFJ', 'ENFP', 'ENTJ', 'INTJ', 'ENFP', 'INFJ', 'ISFJ', 'INTP', 'ENTP', 'INFP', 'ENFP', 'ENFP', 'ISFP', 'INFP', 'INTP', 'ENFP', 'INFJ', 'INTP', 'INTP', 'ESFP', 'INFP', 'INTJ', 'ENTP', 'INTP', 'ENTP', 'INTP', 'ISFP', 'ENFP', 'ENFJ', 'ISFP', 'ENTP', 'INTP', 'ENTP', 'INTJ', 'ENFP', 'INTP', 'INTP', 'ENFP', 'INFJ', 'INFJ', 'INFJ', 'INFP', 'INTP', 'INFP', 'INFJ', 'INFP', 'ENFP', 'ENFJ', 'ESTJ', 'ENFP', 'INTP', 'INFP', 'INFJ', 'INFP', 'INFP', 'ISFJ', 'INTJ', 'INFP', 'INFP', 'ENFP', 'INTP', 'INFP', 'ENTP', 'INFJ', 'INFP', 'ENTP', 'ESTP', 'INFP', 'INFJ', 'ISFP', 'INFP', 'ENTP', 'INFP', 'INFP', 'ENTJ', 'ENFJ', 'INFP', 'INFP', 'INFP', 'ENTP', 'ENFP', 'INFP', 'ENTJ', 'INFJ', 'INFP', 'INTP', 'INFP', 'ENFP', 'INFP', 'ISTP', 'INTP', 'ISFP', 'INFP', 'ESTP', 'ENFP', 'INTP', 'INTJ', 'INFP', 'INFP', 'INTP', 'ESTP', 'ENFP', 'ISTP', 'INTP', 'INTP', 'INTP', 'ENFP', 'ESTP', 'INFP', 'INTJ', 'INFP', 'INTP', 'INFP', 'INFP', 'INTP', 'ISFJ', 'INTP', 'INTJ', 'INFJ', 'INFP', 'INTJ', 'INFP', 'ISTP', 'INFP', 'INFJ', 'INFP', 'INTP', 'ISTP', 'ENTP', 'ENFP', 'INTP', 'ISFP', 'INFP', 'INFP', 'INFP', 'INTP', 'ISTP', 'ISTJ', 'ISFJ', 'INTJ', 'INTP', 'INFP', 'INFP', 'INTP', 'INTP', 'ESFP', 'INFJ', 'INFP', 'INFJ', 'INFP', 'ENFP', 'INFJ', 'INFP', 'INFP', 'INFJ', 'ENTP', 'INFP', 'ENTP', 'ENFP', 'INFJ', 'INFJ', 'INTP', 'INTP', 'INFP', 'ENTJ', 'ENFP', 'INFP', 'INTP', 'ESFP', 'ENTP', 'INFP', 'INFJ', 'INFJ', 'ISTP', 'ENFP', 'INFP', 'INFP', 'INFP', 'ISFP', 'ENTJ', 'ENFP', 'INFP', 'INFP', 'ESTP', 'ENFP', 'ENFP', 'ENTP', 'INFP', 'INFP', 'INTP', 'INFJ', 'INTP', 'ENFP', 'INTP', 'ISFP', 'INFP', 'INTJ', 'INFJ', 'ISFP', 'INFP', 'ENTP', 'INFP', 'INTP', 'INFP', 'ENTP', 'ISTJ', 'INTJ', 'INFP', 'ENFP', 'INTP', 'INTJ', 'INTP', 'INFP', 'INFJ', 'INTP', 'INFP', 'INFJ', 'INTP', 'INFP', 'ENTJ', 'ESTP', 'INFP', 'INTP', 'ENFP', 'INFP', 'INFP', 'ENTP', 'INTJ', 'INFP', 'INTJ', 'INTP', 'INFP', 'INFJ', 'ENFP', 'INTP', 'ENFJ', 'INFP', 'INFP', 'INTP', 'ENFJ', 'INFP', 'ENFJ', 'INTP', 'ENFP', 'ENFJ', 'ENTP', 'ENTP', 'INTP', 'INFP', 'INFP', 'INFJ', 'INFP', 'ISFJ', 'ENTJ', 'INFP', 'ISFJ', 'INFP', 'INTP', 'ENFP', 'INFJ', 'ENFP', 'ENFP', 'ENFP', 'ISTJ', 'ENFP', 'INFJ', 'ENFP', 'ENTP', 'ENTP', 'ESFJ', 'INFP', 'INFP', 'ISFP', 'INFP', 'ENTP', 'ENFP', 'INFJ', 'ENTJ', 'INTP', 'ISFP', 'ISFP', 'ENFJ', 'INTP', 'INTP', 'INTP', 'INFP', 'INTJ', 'INTP', 'INFJ', 'INTP', 'ESFP', 'ENFJ', 'ENFP', 'INFJ', 'INFP', 'ISFP', 'INFP', 'ESFJ', 'INFP', 'ENFP', 'INFJ', 'ENTP', 'INFP', 'ENTP', 'ENFP', 'INFJ', 'ENTP', 'INTP', 'ISTP', 'ENTP', 'INTP', 'ENTP', 'INFP', 'ESTJ', 'INFP', 'ISFP', 'ENFP', 'INTP', 'INFJ', 'ESFP', 'INFJ', 'INTJ', 'ISFP', 'INFP', 'ISFP', 'INTJ', 'INFP', 'ENFP', 'INFP', 'ISFP', 'ENTP', 'ENTP', 'INFP', 'ESFP', 'INTP', 'INTP', 'INTP', 'INTP', 'INFP', 'ENFJ', 'ENFP', 'INFP', 'ENTP', 'ENFP', 'INTP', 'ENFJ', 'INFP', 'INTP', 'ENTP', 'INTP', 'INTJ', 'INFP', 'ISTP', 'INTP', 'INFJ', 'ENFJ', 'INFJ', 'ESFP', 'ISFP', 'INTP', 'INFP', 'ENTP', 'INTJ', 'INFJ', 'ENTP', 'INFJ', 'ENTP', 'INTP', 'ESFP', 'INFP', 'INFP', 'ENTJ', 'INTP', 'INFP', 'INFP', 'ENTP', 'ENFP', 'INFP', 'ENTP', 'INFP', 'INFJ', 'INTJ', 'INTP', 'ENFP', 'INFJ', 'INFP', 'INFP', 'INTP', 'INFP', 'INFP', 'ESFJ', 'INFP', 'INFJ', 'ENFP', 'ENTP', 'ESFJ', 'INFJ', 'ENFP', 'ENTP', 'INFP', 'ENTP', 'ISFP', 'ESFP', 'ENFP', 'ENFJ', 'ENFP', 'INFJ', 'INTP', 'INTJ', 'ENTP', 'INFJ', 'INFP', 'INFP', 'ENTP', 'INFP', 'INFP', 'INTP', 'ISFP', 'INFP', 'ISFP', 'INFJ', 'INFP', 'INTP', 'INTP', 'ENTP', 'ENTP', 'ESTP', 'ENTP', 'INTJ', 'ENTJ', 'INTJ', 'ENFP', 'ENFP', 'INTP', 'INFP', 'ENFP', 'ENTP', 'ENTP', 'INTP', 'ENTP', 'INTP', 'INFP', 'INFP', 'INFP', 'ENFP', 'ESFP', 'ENFP', 'INTP', 'ENFP', 'ISFJ', 'ISTP', 'INFP', 'ENFP', 'INFP', 'INFP', 'INFJ', 'INFP', 'INFP', 'INFP', 'INFP', 'INFP', 'INFP', 'INFP', 'INFJ', 'ENTP', 'ENFJ', 'INFP', 'ENFP', 'INFJ', 'ISFJ', 'ENTP', 'INFP', 'ENTP', 'ENTP', 'INFJ', 'INTP', 'ENTP', 'INTP', 'ISFJ', 'ENFP', 'INTJ', 'ENFJ', 'INFP', 'INTP', 'INTP', 'ISFP', 'ENFP', 'INTJ', 'INTJ', 'ENTJ', 'ISFJ', 'ESTP', 'INFJ', 'ISFP', 'ENTJ', 'INTP', 'INFP', 'INTP', 'INFP', 'INTP', 'INFP', 'INTP', 'ENFP', 'ENTP', 'INFP', 'INFP', 'INFP', 'ENFP', 'INTP', 'ENTP', 'INFP', 'INFP', 'INFP', 'INTJ', 'INFP', 'INTP', 'ISTJ', 'ISFP', 'INTP', 'ENTP', 'ISFP', 'INTJ', 'ENFP', 'INTJ', 'INFJ', 'INFP', 'ENTP', 'INTJ', 'ENTP', 'INFJ', 'INFP', 'INFP', 'INFJ', 'INTP', 'INFP', 'ESFP', 'INFP', 'INTJ', 'ISTP', 'ENTP', 'INTP', 'INTJ', 'INFP', 'ENFP', 'INTJ', 'INFP', 'INFJ', 'INFJ', 'INFP', 'INFP', 'ISFP', 'ESFP', 'INFP', 'ENFP', 'ENTP', 'INFP', 'ENFJ', 'ENFP', 'ISFP', 'ENFP', 'INTJ', 'ISFJ', 'ENFP', 'ENTJ', 'ENFP', 'INFP', 'ENFP', 'INTP', 'INFP', 'INFP', 'ISTP', 'ENFP', 'INFP', 'INTP', 'ENTP', 'ENTP', 'INFP', 'INFP', 'INFP', 'INFP', 'INFJ', 'INFJ', 'INFP', 'ENTP', 'ISTP', 'ISTP', 'INTJ', 'ENTP', 'INFP', 'INFP', 'ISTP', 'INTP', 'INFJ', 'ENFJ', 'INFP', 'INTP', 'ISFJ', 'INTP', 'INFP', 'INFP', 'INTP', 'INTJ', 'ENTP', 'INFP', 'INFP', 'INTP', 'INFP', 'INTP', 'INFJ', 'INFJ', 'INTP', 'INFP', 'INTP', 'INTP', 'ISTP', 'INTP', 'INFP', 'INTP', 'INFJ', 'INTP', 'ENTP', 'ESTP', 'ENFP', 'ENFP', 'INFP', 'INFJ', 'INFP', 'INFJ', 'INTP', 'INFP', 'INFJ', 'INTP', 'INTP', 'ISFP', 'INTJ', 'ENFP', 'INTP', 'ISTP', 'INTP', 'INTP', 'INFP', 'INTP', 'ENFP', 'INFP', 'INFP', 'INFP', 'ISTP', 'INFP', 'INTP', 'INFP', 'ENTP', 'INFP', 'ISFP', 'ENFP', 'INFP', 'ENTP', 'INFP', 'INTP', 'ENFP', 'ENTP', 'ENFP', 'ENFP', 'INFJ', 'ISFP', 'INFJ', 'INFP', 'INFP', 'INFP', 'INFP', 'ENFJ', 'INTP', 'ISFP', 'ISTP', 'INFP', 'ENFP', 'ENFP', 'INFJ', 'ISTP', 'INTP', 'INFJ', 'INFJ', 'ISTP', 'ISFP', 'INFP', 'ISTJ', 'INFP', 'INTJ', 'INTP', 'INFP', 'ENTJ', 'ENFP', 'ENTP', 'ENFP', 'INFP', 'ENTP', 'ENFP', 'ESFJ', 'INFP', 'ENFP', 'INTP', 'ISFP', 'INFP', 'INFJ', 'ENFP', 'ENTP', 'ESTP', 'ESFP', 'INFP', 'INTP', 'INTP', 'INFP', 'INFP', 'INTJ', 'INTP', 'INFP', 'INFP', 'INFJ', 'ENFP', 'INTP', 'INFP', 'INTP', 'ENTJ', 'ENTP', 'INFP', 'INFP', 'ENFJ', 'ENFP', 'ENTP', 'INFJ', 'INTP', 'ENFP', 'INFJ', 'ISFP', 'ISTP', 'INFP', 'INFP', 'INFP', 'ENTJ', 'ISTJ', 'INFP', 'INFP', 'INFP', 'INFJ', 'ENFP', 'ENFP', 'ENFP', 'INFP', 'INTP', 'ENFJ', 'INTP', 'ENTP', 'INTP', 'INFP', 'INFP', 'INTJ', 'INFP', 'ENFJ', 'ENTP', 'INTP', 'INFP', 'INTP', 'INFP', 'INTJ', 'ENTP', 'INFP', 'ENTJ', 'INTP', 'INTJ', 'ENTJ', 'INFJ', 'ENFP', 'INFP', 'INFJ', 'ISTP', 'INFP', 'ENTP', 'ENFP', 'ENFP', 'INTP', 'INFJ', 'ENTP', 'INFP', 'INFP', 'ENFP', 'ENTP', 'INTJ', 'INFP', 'INFJ', 'INTJ', 'ISFP', 'ENFP', 'INTP', 'ENTJ', 'ENTP', 'ISTP', 'ISFJ', 'INFP', 'INFJ', 'INFP', 'ENTP', 'ENFP', 'INFP', 'INFJ', 'ISFP', 'ISFP', 'INFP', 'INFJ', 'INFJ', 'INFJ', 'ENTJ', 'ISFP', 'ENTP', 'ENTJ', 'INFJ', 'ENFP', 'ENTJ', 'ISTP', 'INFP', 'ESTP', 'INTP', 'ENTP', 'INFP', 'ISFP', 'INFP', 'INTP', 'ISFP', 'INFP', 'ESFP', 'ENTJ', 'INTP', 'INFP', 'INTJ', 'ENTJ', 'INTP', 'INTP', 'INFP', 'INFJ', 'ENFP', 'ENFJ', 'ENFJ', 'INTP', 'ENFP', 'INFJ', 'ESTJ', 'ENTJ', 'INFP', 'ENFP', 'INFP', 'ENFP', 'INFJ', 'INFP', 'INFJ', 'INFP', 'INTP', 'ENTP', 'INFP', 'INFP', 'INTP', 'INFJ', 'ENFP', 'ENTJ', 'INTP', 'ENTP', 'ISTP', 'ENTP', 'INTJ', 'INTJ', 'ESTP', 'INTJ', 'INTP', 'ENTP', 'INFP', 'INFJ', 'INTP', 'INFP', 'INFP', 'ENTP', 'INTP', 'INFP', 'ISFP', 'INTP', 'ISFP', 'INFJ', 'ESTP', 'ENFP', 'ENTP', 'ENFP', 'INFP', 'INFP', 'ENTP', 'ENFP', 'INTP', 'ISFP', 'ENTP', 'ISTP', 'INFP', 'ISTP', 'INFP', 'ENFJ', 'ENFP', 'ESTP', 'INTJ', 'INTP', 'INTP', 'INFP', 'INTP', 'INFP', 'INFP', 'ENTP', 'ENFJ', 'INTJ', 'ENTP', 'INFP', 'ISTP', 'INFP', 'ISTP', 'INFP', 'ENFJ', 'INTP', 'ENTP', 'INFP', 'ENTP', 'ESTJ', 'ISTP', 'INFJ', 'INFJ', 'INFP', 'INFP', 'ENFP', 'ENTP', 'ENTP', 'ENFJ', 'ISFP', 'INFP', 'INFJ', 'INFJ', 'INFJ', 'ENFP', 'ENTP', 'INFP', 'ISFP', 'ENFP', 'INTP', 'ENFJ', 'INTP', 'INTP', 'INFP', 'ISFP', 'ENTP', 'INTP', 'INFP', 'INFJ', 'INFJ', 'INFP', 'INTP', 'INFP', 'INFP', 'INFJ', 'INTJ', 'INTP', 'ENTP', 'ISTP', 'INFJ', 'ESFP', 'INTP', 'INTP', 'INTP', 'INFJ', 'ENFP', 'ENFJ', 'ISTP', 'INFP', 'INTJ', 'ENFP', 'ENTP', 'INFP', 'INFP', 'INTP', 'INFJ', 'ESFP', 'INFP', 'INFJ', 'INTP', 'INTJ', 'ISFJ', 'INFP', 'ENFP', 'INFJ', 'ENTP', 'ENTP', 'ENFJ', 'ENFP', 'ENTP', 'ENTP', 'INFP', 'INFP', 'ENTP', 'INFJ', 'INTP', 'ISTP', 'INFP', 'ENTP', 'ESFP', 'ESTP', 'ENFJ', 'INFP', 'ENTJ', 'ENTP', 'INFP', 'INFJ', 'INTJ', 'ENFJ', 'INFP', 'ENFP', 'ENFP', 'ESFP', 'INTJ', 'INTP', 'ENFP', 'INFP', 'ENFJ', 'INTJ', 'INTP', 'INFJ', 'INFP', 'INTP', 'ENFP', 'INFP', 'ENFP', 'INFJ', 'INFP', 'ENTP', 'INFP', 'ISFP', 'ENFJ', 'INFJ', 'INFJ', 'INFP', 'INFP', 'ENFP', 'INFJ', 'ESFJ', 'INTP', 'INTP', 'ISTJ', 'INTP', 'INFP', 'INFJ', 'ENTP', 'ENFJ', 'INFP', 'INFJ', 'INFP', 'INFP', 'INFP', 'INFP', 'INTP', 'INTP', 'ISTP', 'ESFJ', 'INFP', 'ISFP', 'INFP', 'ENFP', 'ENTP', 'ENFP', 'INFJ', 'INTP', 'INTJ', 'INFJ', 'ISTJ', 'ENFP', 'ENFP', 'ENFP', 'INTJ', 'INTP', 'ISFP', 'ESFP', 'ENFP', 'ENFP', 'ENTP', 'INFP', 'INTP', 'ESTP', 'ENTP', 'INFP', 'INFJ', 'ENFP', 'INFP', 'INTP', 'INFJ', 'INTJ', 'INTP', 'ENTP', 'ENTP', 'INTP', 'INFP', 'ENFP', 'ENTJ', 'INFP', 'INFP', 'ENFJ', 'INFP', 'INFJ', 'INTP', 'INFJ', 'INTJ', 'ENTP', 'INFJ', 'INFP', 'INTP', 'INFJ', 'ENTP', 'INTP', 'INTP', 'ENFP', 'INTP', 'INTP', 'INTP', 'INTJ', 'INTP', 'INFJ', 'ENFP', 'INFJ', 'INFP', 'INFP', 'INFJ', 'INFP', 'INFP', 'INFP', 'ENFP', 'INTP', 'ENTP', 'ENTJ', 'INFP', 'INTP', 'INTP', 'INFP', 'ENFP', 'INFP', 'INFJ', 'ENTP', 'INFP', 'INFP', 'INFJ', 'ISTP', 'INFP', 'INFP', 'INTP', 'INFP', 'ENFJ', 'ISTP', 'ISFJ', 'ENTP', 'INFP', 'ENTP', 'ENFP', 'ESTP', 'INFP', 'ENFP', 'INTP', 'INFP', 'ENTP', 'ENTJ', 'INFP', 'INFJ', 'ENFP', 'INFP', 'INFP', 'ENTJ', 'ENFJ', 'INTP', 'ENTP', 'INFP', 'ISFP', 'INFP', 'INFP', 'INTJ', 'ISFP', 'INFP', 'INFJ', 'INFP', 'ENTP', 'ENFP', 'ENTP', 'ESTJ', 'INFP', 'INFP', 'ISFP', 'INFP', 'ISTP', 'INTP', 'INTP', 'INFJ', 'INTP', 'ISTP', 'INTP', 'INFP', 'ENTJ', 'INFJ', 'INTP', 'ENFP', 'INTP', 'INTJ', 'INFP', 'INFP', 'INFJ', 'ESTP', 'INTP', 'ENFP', 'INFP', 'INTJ', 'INFP', 'ISFP', 'INTP', 'INFP', 'INFP', 'INTP', 'INTJ', 'ISTP', 'ENTJ', 'INFP', 'INTP', 'INFP', 'INFJ', 'INTJ', 'INTP', 'ENFP', 'ENTP', 'ENTP', 'ENFP', 'INFP', 'ISTJ', 'INTP', 'INFJ', 'ISTJ', 'INTP']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw5y2PrFJJ-m",
        "outputId": "32f7a272-bd63-4c73-9d49-4fbe9cfb5d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = 0\n",
        "yy = y_test.type.values\n",
        "for i in range(len(predicted)):\n",
        "  if(predicted[i] == yy[i]):\n",
        "    t = t+1\n",
        "print(t/len(predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F1hiKbkJa69",
        "outputId": "c8512fe3-2f85-42cd-b574-a659290fc760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5054755043227666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mh9vwQxtGw23"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}